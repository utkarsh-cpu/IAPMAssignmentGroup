{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "collapsed": true,
    "id": "_VfbYKziimKT",
    "outputId": "fa7a4bfa-2f7b-4554-93ed-a2dff885b6a8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nIAPM Portfolio discovery\\nBharath, Chelsea, Gaurav, Vikram, Utkarsh, Yash\\n\\n2009-2021 dataset link: https://drive.google.com/file/d/1yJuY2SF3sCllibGXeyoNNzS6v2j7g08s/view?usp=sharing\\n01/08/24-31/12/25 dataset link: https://drive.google.com/file/d/17DOkvtHBUXqDMvnWVTku1TfRFNEKolS7/view?usp=sharing\\n01/08/24-25/02/26 dataset link: https://drive.google.com/file/d/1edQni7obD5aQqfgqh_-bgz0NOOj6tXG7/view?usp=sharing\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "IAPM Portfolio discovery\n",
    "Bharath, Chelsea, Gaurav, Vikram, Utkarsh, Yash\n",
    "\n",
    "2009-2021 dataset link: https://drive.google.com/file/d/1yJuY2SF3sCllibGXeyoNNzS6v2j7g08s/view?usp=sharing\n",
    "01/08/24-31/12/25 dataset link: https://drive.google.com/file/d/17DOkvtHBUXqDMvnWVTku1TfRFNEKolS7/view?usp=sharing\n",
    "01/08/24-25/02/26 dataset link: https://drive.google.com/file/d/1edQni7obD5aQqfgqh_-bgz0NOOj6tXG7/view?usp=sharing\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hGgt5ASxpnML",
    "outputId": "db38dffe-1c5b-4069-d4e4-176ebdd33c30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ZIP from Google Drive...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1edQni7obD5aQqfgqh_-bgz0NOOj6tXG7\n",
      "From (redirected): https://drive.google.com/uc?id=1edQni7obD5aQqfgqh_-bgz0NOOj6tXG7&confirm=t&uuid=ad1652db-1225-4a71-8abd-3aaddcef539b\n",
      "To: /Users/utkarsh_kaushik/practice/python/IAPMAssignmentGroup/bse_data/stock_data_24_26_25Feb26.zip\n",
      "100%|██████████| 89.3M/89.3M [00:05<00:00, 17.8MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ZIP...\n",
      "Extraction complete.\n",
      "Scanning CSV files...\n",
      "Strategy: None (returning ALL stocks)\n",
      "Strategy: None\n",
      "Selected 9163 stocks\n",
      "Final dataset shape: (363, 9164)\n",
      "Available: 33\n",
      "Missing: 9\n",
      "\n",
      "Missing symbols:\n",
      "['ASLIND', 'AXISILVER', 'KAPSTON', 'EGOLD', 'KRISHANA', 'CMMIPL', 'GVT&D', 'UNIHEALTH', 'VMARCIND']\n",
      "symbol       date   TAKE  BANCOINDIA  KESORAMIND     BEL  LOTUSEYE  CRAFTSMAN  \\\n",
      "0      2024-08-01  19.81      744.00      218.60  311.15     67.03    5542.25   \n",
      "1      2024-08-02  19.68      728.90      213.95  302.95     66.02    5354.00   \n",
      "2      2024-08-05  18.99      680.65      209.95  290.10     64.06    5184.25   \n",
      "3      2024-08-06  18.46      669.50      210.00  287.30     63.11    5176.75   \n",
      "4      2024-08-07  19.73      683.80      212.85  300.25     67.88    5196.65   \n",
      "\n",
      "symbol     CUB  QGOLDHALF  SILVER  ...     LTF  ABINFRA  UNIONBANK  BANKINDIA  \\\n",
      "0       171.95      58.77   85.33  ...  176.55      NaN     135.20     126.05   \n",
      "1       166.85      59.35   85.29  ...  177.05      NaN     133.30     126.15   \n",
      "2       162.40      58.47   82.28  ...  168.50      NaN     125.65     122.25   \n",
      "3       162.35      58.42   80.77  ...  167.15      NaN     122.55     118.95   \n",
      "4       163.70      58.00   81.04  ...  169.50      NaN     122.25     118.90   \n",
      "\n",
      "symbol  CUPID  SMSPHARMA  TFCILTD  DCBBANK  KARURVYSYA   TCIEXP  \n",
      "0       92.04     303.35   185.65   124.85      225.95  1212.30  \n",
      "1       90.60     312.55   179.90   124.55      219.00  1186.25  \n",
      "2       87.07     309.20   170.95   119.05      210.10  1135.40  \n",
      "3       91.42     276.30   170.00   119.30      206.95  1137.90  \n",
      "4       95.99     295.80   173.50   119.00      215.10  1159.00  \n",
      "\n",
      "[5 rows x 34 columns]\n",
      "2024-08-01 00:00:00\n",
      "2026-02-25 00:00:00\n",
      "\n",
      "===== STEP 1: Sharpe filtering =====\n",
      "Reduced from 33 to 30 stocks by Sharpe\n",
      "\n",
      "===== STEP 2: Correlation pruning =====\n",
      "Reduced to 30 stocks after correlation pruning\n",
      "\n",
      "Testing heuristic search over reduced space...\n",
      "\n",
      "===== STEP 3: Beam search =====\n",
      "Depth 1/10 | Processed 30 | Checked 30 | Dropped 0 | Best GMVP risk=0.015022, return=0.002461 | Best MRR return=0.006428, risk=0.039133\n",
      "Depth 2/10 | Processed 320 | Checked 320 | Dropped 0 | Best GMVP risk=0.011612, return=0.001630 | Best MRR return=0.003218, risk=0.013680\n",
      "Depth 3/10 | Processed 600 | Checked 600 | Dropped 0 | Best GMVP risk=0.010969, return=0.002058 | Best MRR return=0.003850, risk=0.014148\n",
      "Depth 4/10 | Processed 870 | Checked 870 | Dropped 0 | Best GMVP risk=0.010897, return=0.002204 | Best MRR return=0.003739, risk=0.013339\n",
      "Depth 5/10 | Processed 1130 | Checked 1130 | Dropped 0 | Best GMVP risk=0.010567, return=0.002250 | Best MRR return=0.003652, risk=0.012758\n",
      "Depth 6/10 | Processed 1380 | Checked 1380 | Dropped 0 | Best GMVP risk=0.010403, return=0.002298 | Best MRR return=0.003620, risk=0.012553\n",
      "Depth 7/10 | Processed 1620 | Checked 1620 | Dropped 0 | Best GMVP risk=0.010349, return=0.002316 | Best MRR return=0.003588, risk=0.012400\n",
      "Depth 8/10 | Processed 1850 | Checked 1850 | Dropped 0 | Best GMVP risk=0.010243, return=0.002308 | Best MRR return=0.003548, risk=0.012242\n",
      "Depth 9/10 | Processed 2070 | Checked 2070 | Dropped 0 | Best GMVP risk=0.009987, return=0.002245 | Best MRR return=0.003542, risk=0.012217\n",
      "Depth 10/10 | Processed 2280 | Checked 2280 | Dropped 0 | Best GMVP risk=0.009984, return=0.002249 | Best MRR return=0.003542, risk=0.012217\n",
      "\n",
      "===== STEP 4: Random refinement =====\n",
      "Random 4000/5000 | Processed 3012 | Checked 3012 | Dropped 3269 | Best GMVP risk=0.009934, return=0.002109 | Best MRR return=0.003542, risk=0.012217\n",
      "\n",
      "===== FINAL SUMMARY =====\n",
      "Total combinations (original space): 30045015\n",
      "Processed: 3205\n",
      "Valid (checked): 3205\n",
      "Dropped: 4075\n",
      "Drop rate: 127.15%\n",
      "\n",
      "======================================================================\n",
      "BEST GMVP PORTFOLIO\n",
      "======================================================================\n",
      "\n",
      "Companies:\n",
      "  UNIONBANK\n",
      "  CUPID\n",
      "  AVANTIFEED\n",
      "  HAPPYFORGE\n",
      "  CRAFTSMAN\n",
      "  SABEVENTS\n",
      "  QGOLDHALF\n",
      "  TAKE\n",
      "  CUB\n",
      "  BANKINDIA\n",
      "\n",
      "GMVP Portfolio Weights:\n",
      "----------------------------------------\n",
      "UNIONBANK       :    1.593 %\n",
      "CUPID           :    7.089 %\n",
      "AVANTIFEED      :    0.281 %\n",
      "HAPPYFORGE      :   18.224 %\n",
      "CRAFTSMAN       :    8.232 %\n",
      "SABEVENTS       :    5.133 %\n",
      "QGOLDHALF       :   42.467 %\n",
      "TAKE            :    4.261 %\n",
      "CUB             :    8.847 %\n",
      "BANKINDIA       :    3.874 %\n",
      "\n",
      "GMVP Performance:\n",
      "  Daily Return  :   0.2042 %\n",
      "  Daily Risk    :   0.9800 %\n",
      "  Annual Return :    51.46 %\n",
      "  Annual Risk   :    15.56 %\n",
      "\n",
      "MRR Portfolio (Max Sharpe) Weights:\n",
      "----------------------------------------\n",
      "UNIONBANK       :    0.158 %\n",
      "CUPID           :   21.425 %\n",
      "AVANTIFEED      :    4.361 %\n",
      "HAPPYFORGE      :    0.000 %\n",
      "CRAFTSMAN       :    3.975 %\n",
      "SABEVENTS       :    8.250 %\n",
      "QGOLDHALF       :   47.710 %\n",
      "TAKE            :    7.840 %\n",
      "CUB             :    6.282 %\n",
      "BANKINDIA       :    0.000 %\n",
      "\n",
      "MRR Performance:\n",
      "  Daily Return  :   0.2927 %\n",
      "  Daily Risk    :   1.1423 %\n",
      "  Annual Return :    73.75 %\n",
      "  Annual Risk   :    18.13 %\n",
      "\n",
      "Sharpe Ratio:\n",
      "  Daily Sharpe  :   0.2338\n",
      "  Annual Sharpe :   3.7112\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "BEST MRR PORTFOLIO\n",
      "======================================================================\n",
      "\n",
      "Companies:\n",
      "  BGRENERGY\n",
      "  QGOLDHALF\n",
      "  CUPID\n",
      "  SABEVENTS\n",
      "  LUMAXIND\n",
      "  POWERINDIA\n",
      "  TAKE\n",
      "  CUB\n",
      "  AVANTIFEED\n",
      "\n",
      "GMVP Portfolio Weights:\n",
      "----------------------------------------\n",
      "BGRENERGY       :    2.868 %\n",
      "QGOLDHALF       :   47.900 %\n",
      "CUPID           :   10.126 %\n",
      "SABEVENTS       :    7.178 %\n",
      "LUMAXIND        :    6.218 %\n",
      "POWERINDIA      :    2.720 %\n",
      "TAKE            :    4.721 %\n",
      "CUB             :   14.453 %\n",
      "AVANTIFEED      :    3.816 %\n",
      "\n",
      "GMVP Performance:\n",
      "  Daily Return  :   0.2757 %\n",
      "  Daily Risk    :   1.0657 %\n",
      "  Annual Return :    69.47 %\n",
      "  Annual Risk   :    16.92 %\n",
      "\n",
      "MRR Portfolio (Max Sharpe) Weights:\n",
      "----------------------------------------\n",
      "BGRENERGY       :   14.409 %\n",
      "QGOLDHALF       :   42.609 %\n",
      "CUPID           :   20.336 %\n",
      "SABEVENTS       :    6.916 %\n",
      "LUMAXIND        :    6.512 %\n",
      "POWERINDIA      :    3.448 %\n",
      "TAKE            :    2.702 %\n",
      "CUB             :    2.480 %\n",
      "AVANTIFEED      :    0.588 %\n",
      "\n",
      "MRR Performance:\n",
      "  Daily Return  :   0.3542 %\n",
      "  Daily Risk    :   1.2217 %\n",
      "  Annual Return :    89.26 %\n",
      "  Annual Risk   :    19.39 %\n",
      "\n",
      "Sharpe Ratio:\n",
      "  Daily Sharpe  :   0.2689\n",
      "  Annual Sharpe :   4.2693\n",
      "======================================================================\n",
      "Warning: These companies were not found:\n",
      "['OSIAJEE', 'GOLDETF', 'CIANAGRO', 'GNRL', 'INDOKEM', 'ARIHANT', 'LKPFIN', 'JSWHL']\n",
      "\n",
      "Excel file created: best_mrr3.xlsx\n",
      "Columns exported: ['date', 'CUPID', 'BGRENERGY']\n",
      "Total rows: 346\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import zipfile\n",
    "import requests\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gdown\n",
    "import glob\n",
    "import math\n",
    "\n",
    "NIFTY50_SYMBOLS = [\n",
    "    \"ADANIENT\", \"ADANIPORTS\", \"APOLLOHOSP\", \"ASIANPAINT\", \"AXISBANK\",\n",
    "    \"BAJAJ-AUTO\", \"BAJFINANCE\", \"BAJAJFINSV\", \"BPCL\", \"BHARTIARTL\",\n",
    "    \"BRITANNIA\", \"CIPLA\", \"COALINDIA\", \"DIVISLAB\", \"DRREDDY\",\n",
    "    \"EICHERMOT\", \"GRASIM\", \"HCLTECH\", \"HDFCBANK\", \"HDFCLIFE\",\n",
    "    \"HEROMOTOCO\", \"HINDALCO\", \"HINDUNILVR\", \"ICICIBANK\", \"ITC\",\n",
    "    \"INDUSINDBK\", \"INFY\", \"JSWSTEEL\", \"KOTAKBANK\", \"LT\",\n",
    "    \"LTIM\", \"M&M\", \"MARUTI\", \"NTPC\", \"NESTLEIND\",\n",
    "    \"ONGC\", \"POWERGRID\", \"RELIANCE\", \"SBILIFE\", \"SBIN\",\n",
    "    \"SUNPHARMA\", \"TCS\", \"TATACONSUM\", \"TATAMOTORS\", \"TATASTEEL\",\n",
    "    \"TECHM\", \"TITAN\", \"ULTRACEMCO\", \"UPL\", \"WIPRO\"\n",
    "]\n",
    "\n",
    "CHELSEA01 = [\"ASLIND\", \"TAKE\", \"BANCOINDIA\",\"KESORAMIND\", \"BEL\", \"LOTUSEYE\", \"AXISILVER\",\"CRAFTSMAN\",\n",
    "             \"CUB\", \"QGOLDHALF\", \"SILVER\", \"KAPSTON\", \"SABEVENTS\", \"TDPOWERSYS\", \"BLISSGVS\", \"SANSERA\",\n",
    "             \"LUMAXIND\", \"MRPL\", \"PRECWIRE\", \"EGOLD\", \"KRISHANA\", \"NETWEB\", \"BGRENERGY\", \"HAPPYFORGE\", \"GENCON\",\n",
    "             \"CMMIPL\", \"AVANTIFEED\", \"BHARATWIRE\", \"GVT&D\", \"POWERINDIA\", \"LTF\", \"ABINFRA\", \"UNIONBANK\", \"BANKINDIA\",\n",
    "             \"CUPID\", \"SMSPHARMA\", \"UNIHEALTH\", \"VMARCIND\", \"TFCILTD\", \"DCBBANK\", \"KARURVYSYA\", \"TCIEXP\"]\n",
    "\n",
    "Bharath = [\"ACUTAAS\", \"PARKHOTELS\", \"APOLLOHOSP\", \"BAJAJ-AUTO\", \"CANROBO\",\n",
    "       \"CAMS\", \"CONTROLPR\", \"CROMPTON\", \"DABUR\", \"GRSE\",\n",
    "       \"MEDANTA\", \"HEG\", \"KOTAKBANK\", \"LT\", \"LICHSGFIN\",\n",
    "       \"REPCOHOME\", \"SAILIFE\", \"SKYGOLD\", \"SPAL\", \"SBIN\",\n",
    "       \"V2RETAIL\", \"WABAG\", \"VBL\"]\n",
    "\n",
    "COMPANY_STARTING_WITH_A_SYMBOLS = [\n",
    "    \"A2ZMES\", \"AANJANEYA\", \"AARTIDRUGS\", \"AARTIIND\", \"AARVEEDEN\", \"ABAN\",\n",
    "    \"ABB\", \"ABCIL\", \"ABGSHIP\", \"ABIRLANUVO\", \"ACC\", \"ACE\", \"ACKRUTI\", \"ADANIENT\",\n",
    "    \"ACROPETAL\", \"ADANIPOWER\", \"ADFFOODS\", \"ADHUNIK\", \"ADORWELD\", \"ADSL\",\n",
    "    \"ADVANIHOTR\", \"ADVANTA\", \"AEGISCHEM\", \"AFL\", \"AFTEK\", \"AGCNET\", \"AGRODUTCH\",\n",
    "    \"AHLEAST\", \"AHLUCONT\", \"AHLWEST\", \"AHMEDFORGE\", \"AIAENG\", \"AICHAMP\", \"AJANTPHARM\",\n",
    "    \"AJMERA\", \"AKSHOPTFBR\", \"AKZOINDIA\", \"ALBK\", \"ALCHEM\", \"ALEMBICLTD\",\n",
    "    \"ALFALAVAL\", \"ALICON\", \"ALKALI\", \"ALKYLAMINE\", \"ALLCARGO\", \"ALLSEC\",\n",
    "    \"ALMONDZ\", \"ALOKTEXT\", \"ALPHAGEO\", \"AMAR\", \"AMARAJABAT\", \"ALPSINDUS\", \"AMBIKCO\",\n",
    "    \"AMBUJACEM\", \"AMDIND\", \"AMTEKAUTO\", \"AMTEKINDIA\", \"ANANTRAJ\", \"ANDHRABANK\",\n",
    "    \"ANDHRSUGAR\", \"ANGIND\", \"ANIKINDS\", \"ANDHRACEMT\", \"ANKURDRUGS\", \"ANSALAPI\",\n",
    "    \"ANSALHSG\", \"ANTGRAPHIC\", \"APARINDS\", \"APCOTEXIND\", \"APIL\", \"APOLLOHOSP\",\n",
    "    \"APOLLOTYRE\", \"APPAPER\", \"APTECHT\", \"AQUA\", \"ARCHIDPLY\", \"ARCHIES\", \"AREVAT&D\"\n",
    "]\n",
    "\n",
    "UTKARSH_TICKERS = [\"OSIAJEE\",\n",
    "\"GOLDETF\",\n",
    "\"CIANAGRO\",\n",
    "\"GNRL\",\n",
    "\"CUPID\",\n",
    "\"INDOKEM\",\n",
    "\"ARIHANT\",\n",
    "\"LKPFIN\",\n",
    "\"BGRENERGY\",\n",
    "\"JSWHL\"]\n",
    "\n",
    "def find_data_root(base_folder):\n",
    "    \"\"\"\n",
    "    Recursively search for Companies_list.csv to detect valid data root.\n",
    "    \"\"\"\n",
    "    for root, dirs, files in os.walk(base_folder):\n",
    "        if \"Companies_list.csv\" in files and \"HISTORICAL_DATA\" in dirs:\n",
    "            return root\n",
    "    return None\n",
    "\n",
    "def download_and_extract_google_drive_zip_1(file_id, extract_to=\"stock_data\"):\n",
    "    \"\"\"\n",
    "    Downloads and extracts Google Drive ZIP safely.\n",
    "    Automatically detects correct nested root folder.\n",
    "    \"\"\"\n",
    "    os.makedirs(extract_to, exist_ok=True)\n",
    "    existing_root = find_data_root(extract_to)\n",
    "    if existing_root is not None:\n",
    "        print(f\"Data already exists at: {existing_root}\")\n",
    "        print(\"Skipping download.\")\n",
    "        return existing_root\n",
    "    zip_path = os.path.join(extract_to, \"stock_data.zip\")\n",
    "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "    print(\"Downloading from Google Drive...\")\n",
    "    gdown.download(url, zip_path, quiet=False)\n",
    "    print(\"Extracting zip...\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "    print(\"Extraction complete.\")\n",
    "    for root, dirs, files in os.walk(extract_to): # recursively find Companies_list.csv\n",
    "        if \"Companies_list.csv\" in files:\n",
    "            print(\"Correct data root detected:\", root)\n",
    "            return root\n",
    "    raise Exception(\"Could not find Companies_list.csv in extracted contents\")\n",
    "\n",
    "def load_company_csv_strict(path: str, symbol: str) -> pd.DataFrame | None:\n",
    "    \"\"\"\n",
    "    Load single CSV only if it contains 'Date' and a close-like column.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        raw = pd.read_csv(path, low_memory=False)\n",
    "        raw.columns = [str(c).strip() for c in raw.columns]\n",
    "        # find exact date column (case-insensitive)\n",
    "        date_col = next((c for c in raw.columns if c.lower() == \"date\"), None)\n",
    "        if date_col is None:\n",
    "            # skip\n",
    "            # print(f\"Skipping {symbol}: no Date column\")\n",
    "            return None\n",
    "        raw[date_col] = pd.to_datetime(raw[date_col], errors=\"coerce\")\n",
    "        raw = raw.dropna(subset=[date_col])\n",
    "        close_candidates = [c for c in raw.columns if c.lower() in (\"adj_close\",\"adj close\",\"close\",\"close_price\",\"close price\")]\n",
    "        if not close_candidates:\n",
    "            # skip\n",
    "            # print(f\"Skipping {symbol}: no close column\")\n",
    "            return None\n",
    "        close_col = close_candidates[0]\n",
    "        df = raw[[date_col, close_col]].rename(columns={date_col: \"Date\", close_col: symbol})\n",
    "        df = df.dropna().drop_duplicates(subset=[\"Date\"]).sort_values(\"Date\").set_index(\"Date\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {symbol} from {path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def read_stock_data_from_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Reads stock dataset using:\n",
    "\n",
    "    folder_path/\n",
    "        Companies_list.csv\n",
    "        HISTORICAL_DATA/*.csv\n",
    "\n",
    "    Returns optimizer-compatible dataframe:\n",
    "    date, SYMBOL1, SYMBOL2, SYMBOL3...\n",
    "    \"\"\"\n",
    "\n",
    "    companies_csv = os.path.join(folder_path, \"Companies_list.csv\")\n",
    "    hist_dir = os.path.join(folder_path, \"HISTORICAL_DATA\")\n",
    "    if not os.path.exists(companies_csv):\n",
    "        raise Exception(\"Companies_list.csv not found\")\n",
    "    if not os.path.exists(hist_dir):\n",
    "        raise Exception(\"HISTORICAL_DATA folder not found\")\n",
    "    companies_df = pd.read_csv(companies_csv)\n",
    "    companies_df.columns = [c.strip() for c in companies_df.columns]\n",
    "    symbol_col = next(\n",
    "        (c for c in companies_df.columns\n",
    "         if c.lower() in (\"symbol\", \"ticker\", \"company\", \"stock\", \"code\")),\n",
    "        companies_df.columns[0]\n",
    "    )\n",
    "    symbols = companies_df[symbol_col].astype(str).tolist()\n",
    "    files = glob.glob(os.path.join(hist_dir, \"*_data.csv\"))\n",
    "    file_map = {}\n",
    "    for f in files:\n",
    "        name = os.path.basename(f)\n",
    "        prefix = name.replace(\"_data.csv\", \"\")\n",
    "        file_map[prefix.upper()] = f\n",
    "    frames = []\n",
    "    loaded_symbols = []\n",
    "    for symbol in symbols:\n",
    "        symbol_upper = symbol.upper()\n",
    "        if symbol_upper not in file_map:\n",
    "            continue\n",
    "        df = load_company_csv_strict(file_map[symbol_upper], symbol)\n",
    "        if df is not None and not df.empty:\n",
    "            frames.append(df)\n",
    "            loaded_symbols.append(symbol)\n",
    "    if not frames:\n",
    "        raise Exception(\"No valid CSV files found after strict cleaning\")\n",
    "    panel = pd.concat(frames, axis=1, join=\"outer\")\n",
    "    panel = panel.sort_index().ffill()\n",
    "    # convert to optimizer format\n",
    "    panel.reset_index(inplace=True)\n",
    "    panel.rename(columns={\"Date\": \"date\"}, inplace=True)\n",
    "    panel[\"date\"] = panel[\"date\"].astype(str)\n",
    "    print(f\"Loaded {len(loaded_symbols)} valid symbols\")\n",
    "    return panel\n",
    "\n",
    "def download_and_extract_google_drive_zip_2(file_id, extract_to=\"bse_data\"):\n",
    "    os.makedirs(extract_to, exist_ok=True)\n",
    "    zip_path = os.path.join(extract_to, \"stock_data_24_26_25Feb26.zip\")\n",
    "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "    if not os.path.exists(zip_path):\n",
    "        print(\"Downloading ZIP from Google Drive...\")\n",
    "        gdown.download(url, zip_path, quiet=False)\n",
    "    print(\"Extracting ZIP...\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "    print(\"Extraction complete.\")\n",
    "    # Return actual CSV folder directly\n",
    "    csv_folder = os.path.join(extract_to, \"stock_data_24_26_25Feb26\")\n",
    "    return csv_folder\n",
    "\n",
    "def select_top_by_turnover(df, top_n=100):\n",
    "    avg_turnover = (\n",
    "        df.groupby(\"symbol\")[\"turnover\"]\n",
    "        .mean()\n",
    "        .sort_values(ascending=False)\n",
    "    )\n",
    "    return avg_turnover.head(top_n).index.tolist()\n",
    "\n",
    "def select_random(df, top_n=100, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    symbols = df[\"symbol\"].unique()\n",
    "    return list(np.random.choice(symbols, size=min(top_n, len(symbols)), replace=False))\n",
    "\n",
    "def select_price_filter(df, min_price=50):\n",
    "    avg_price = df.groupby(\"symbol\")[\"close\"].mean()\n",
    "    return avg_price[avg_price > min_price].index.tolist()\n",
    "\n",
    "def select_turnover_and_price(df, top_n=150, min_price=50):\n",
    "    df_filtered = df[df[\"close\"] > min_price]\n",
    "    return select_top_by_turnover(df_filtered, top_n=top_n)\n",
    "\n",
    "def read_bse_bhavcopy_folder(\n",
    "    folder_path,\n",
    "    strategy=None,\n",
    "    strategy_params=None\n",
    "):\n",
    "    \"\"\"\n",
    "    strategy:\n",
    "        \"top_turnover\"\n",
    "        \"random\"\n",
    "        \"price_filter\"\n",
    "        \"turnover_price\"\n",
    "        None  → no filtering (ALL stocks)\n",
    "    returns data in\n",
    "    Date firm1 firm2...\n",
    "    ...  price price...\n",
    "    \"\"\"\n",
    "    if strategy_params is None:\n",
    "        strategy_params = {}\n",
    "    print(\"Scanning CSV files...\")\n",
    "    csv_files = glob.glob(os.path.join(folder_path, \"**/*.[cC][sS][vV]\"), recursive=True)\n",
    "    if not csv_files:\n",
    "        raise Exception(\"No CSV files found.\")\n",
    "    all_data = []\n",
    "    for file in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file, low_memory=False)\n",
    "            required_cols = [\"TradDt\", \"TckrSymb\", \"ClsPric\", \"TtlTrfVal\"]\n",
    "            if not all(col in df.columns for col in required_cols):\n",
    "                continue\n",
    "            df = df[required_cols].copy()\n",
    "            df[\"TradDt\"] = pd.to_datetime(df[\"TradDt\"], errors=\"coerce\")\n",
    "            df[\"TtlTrfVal\"] = pd.to_numeric(df[\"TtlTrfVal\"], errors=\"coerce\")\n",
    "            df = df.dropna(subset=[\"TradDt\", \"TckrSymb\", \"ClsPric\", \"TtlTrfVal\"])\n",
    "            df.rename(columns={\n",
    "                \"TradDt\": \"date\",\n",
    "                \"TckrSymb\": \"symbol\",\n",
    "                \"ClsPric\": \"close\",\n",
    "                \"TtlTrfVal\": \"turnover\"\n",
    "            }, inplace=True)\n",
    "\n",
    "            all_data.append(df)\n",
    "        except:\n",
    "            continue\n",
    "    if not all_data:\n",
    "        raise Exception(\"No valid bhav copy data found.\")\n",
    "    combined = pd.concat(all_data, ignore_index=True)\n",
    "    # Strategy Selection\n",
    "    if strategy is None:\n",
    "      print(\"Strategy: None (returning ALL stocks)\")\n",
    "      selected_symbols = combined[\"symbol\"].unique().tolist()\n",
    "    elif strategy == \"top_turnover\":\n",
    "        selected_symbols = select_top_by_turnover(combined, **strategy_params)\n",
    "    elif strategy == \"random\":\n",
    "        selected_symbols = select_random(combined, **strategy_params)\n",
    "    elif strategy == \"price_filter\":\n",
    "        selected_symbols = select_price_filter(combined, **strategy_params)\n",
    "    elif strategy == \"turnover_price\":\n",
    "        selected_symbols = select_turnover_and_price(combined, **strategy_params)\n",
    "    elif strategy is None:\n",
    "        selected_symbols = combined[\"symbol\"].unique().tolist()\n",
    "    else:\n",
    "        raise ValueError(\"Unknown strategy\")\n",
    "    print(f\"Strategy: {strategy}\")\n",
    "    print(f\"Selected {len(selected_symbols)} stocks\")\n",
    "    combined = combined[combined[\"symbol\"].isin(selected_symbols)]\n",
    "    # Pivot\n",
    "    panel = combined.pivot_table(\n",
    "        index=\"date\",\n",
    "        columns=\"symbol\",\n",
    "        values=\"close\",\n",
    "        aggfunc=\"first\"\n",
    "    )\n",
    "    panel = panel.sort_index().ffill()\n",
    "    panel.reset_index(inplace=True)\n",
    "    panel[\"date\"] = panel[\"date\"].astype(str)\n",
    "    print(f\"Final dataset shape: {panel.shape}\")\n",
    "    return panel\n",
    "\n",
    "def filter_dataset(\n",
    "    df,\n",
    "    start_date=None,\n",
    "    end_date=None,\n",
    "    company_codes=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Filters dataset based on tunable parameters...\n",
    "\n",
    "    INPUTS:\n",
    "    df            : pandas DataFrame dataset in specified format\n",
    "    start_date    : str or None starting date to include\n",
    "    end_date      : str or None ending date to include\n",
    "    company_codes : list[str] or None list of company columns to keep\n",
    "\n",
    "    OUTPUT:\n",
    "    filtered_df   : pandas DataFrame\n",
    "\n",
    "    INPUT DATAFRAME FORMAT:\n",
    "    First column      : date (string / datetime / month)\n",
    "    Remaining columns : stock prices\n",
    "    Each row          : time snapshot\n",
    "    Each column       : stock price of that company at that time\n",
    "    example           :\n",
    "    date,    AAPL, MSFT, GOOG, AMZN\n",
    "    2020-01, 100, 200, 300, 400\n",
    "    2020-02, 105, 210, 290, 420\n",
    "    2020-03, 110, 220, 310, 430\n",
    "    \"\"\"\n",
    "\n",
    "    filtered = df.copy()\n",
    "    filtered['date'] = pd.to_datetime(filtered['date']) # Ensure date column is datetime for comparison\n",
    "    if start_date is not None: # Filter by start date\n",
    "        filtered = filtered[filtered['date'] >= pd.to_datetime(start_date)]\n",
    "    if end_date is not None: # Filter by end date\n",
    "        filtered = filtered[filtered['date'] <= pd.to_datetime(end_date)]\n",
    "    if company_codes is not None: # Filter company columns\n",
    "        filtered = filtered[['date'] + company_codes]\n",
    "    filtered = filtered.reset_index(drop=True) # Reset index\n",
    "    return filtered\n",
    "\n",
    "def compute_returns(price_df):\n",
    "    \"\"\"\n",
    "    Converts price data into return data...\n",
    "\n",
    "    INPUT:\n",
    "    price_df : pandas DataFrame\n",
    "\n",
    "    RETURN DEFINTITION:\n",
    "    r_t = (P_t - P_(t-1)) / P_(t-1)\n",
    "\n",
    "    OUTPUT:\n",
    "    returns_df : pandas DataFrame\n",
    "    \"\"\"\n",
    "    prices = price_df.copy()\n",
    "    prices.set_index('date', inplace=True)\n",
    "    # Remove columns that contain ANY NaN in the selected window\n",
    "    prices = prices.dropna(axis=1, how=\"any\")\n",
    "    returns_df = prices.pct_change().dropna()\n",
    "    return returns_df\n",
    "\n",
    "def portfolio_optimizer(returns_df, risk_free_rate=0.0, allow_short=True):\n",
    "    \"\"\"\n",
    "    Performs closed-form portfolio optimisation.\n",
    "\n",
    "    INPUT:\n",
    "    returns_df      : pandas DataFrame\n",
    "    risk_free_rate  : float\n",
    "\n",
    "    OUTPUT:\n",
    "    results         : dictionary\n",
    "                        mean return vector\n",
    "                        covariance matrix\n",
    "                        GMVP portfolio (min variance)\n",
    "                        MRR portfolio (max sharpe)\n",
    "    \"\"\"\n",
    "\n",
    "    returns = returns_df.values # Convert to numpy\n",
    "\n",
    "    # edge case: if portfolio by chance has only one stock\n",
    "    if returns.shape[1] == 1:\n",
    "      mu = returns.mean(axis=0)[0]\n",
    "      sigma = returns.std(axis=0)[0]\n",
    "      return {\n",
    "          \"mean_returns\": np.array([mu]),\n",
    "          \"std_returns\": np.array([sigma]),\n",
    "          \"covariance_matrix\": np.array([[sigma**2]]),\n",
    "          \"gmvp\": {\n",
    "              \"weights\": np.array([1.0]),\n",
    "              \"return\": mu,\n",
    "              \"risk\": sigma\n",
    "          },\n",
    "          \"mrr\": {\n",
    "              \"weights\": np.array([1.0]),\n",
    "              \"return\": mu,\n",
    "              \"risk\": sigma,\n",
    "              \"sharpe\": (mu - risk_free_rate) / sigma\n",
    "          }\n",
    "      }\n",
    "\n",
    "    mu = np.mean(returns, axis=0) # Mean returns vector\n",
    "    Sigma = np.cov(returns, rowvar=False) # Covariance matrix\n",
    "    Sigma_inv = np.linalg.inv(Sigma) # Inverse covariance\n",
    "    n = len(mu)\n",
    "    ones = np.ones(n)\n",
    "\n",
    "    # GMVP Portfolio\n",
    "    w_gmvp = Sigma_inv @ ones\n",
    "    w_gmvp = w_gmvp / (ones.T @ Sigma_inv @ ones)\n",
    "    if not allow_short: # enforce long-only constraint if short selling not allowed\n",
    "      w_gmvp = np.maximum(w_gmvp, 0)\n",
    "      w_gmvp = w_gmvp / np.sum(w_gmvp)\n",
    "    gmvp_return = w_gmvp @ mu\n",
    "    gmvp_var = w_gmvp.T @ Sigma @ w_gmvp\n",
    "    gmvp_std = np.sqrt(gmvp_var)\n",
    "\n",
    "    # MRR Portfolio\n",
    "    excess_returns = mu - risk_free_rate\n",
    "    w_tan = Sigma_inv @ excess_returns\n",
    "    w_tan = w_tan / (ones.T @ Sigma_inv @ excess_returns)\n",
    "    if not allow_short: # enforce long-only constraint if short selling not allowed\n",
    "      w_tan = np.maximum(w_tan, 0)\n",
    "      w_tan = w_tan / np.sum(w_tan)\n",
    "    tan_return = w_tan @ mu\n",
    "    tan_var = w_tan.T @ Sigma @ w_tan\n",
    "    tan_std = np.sqrt(tan_var)\n",
    "    tan_sharpe = (tan_return - risk_free_rate) / tan_std\n",
    "\n",
    "    stock_std = np.sqrt(np.diag(Sigma)) # Individual stock stats\n",
    "    results = {\n",
    "        \"mean_returns\": mu,\n",
    "        \"std_returns\": stock_std,\n",
    "        \"covariance_matrix\": Sigma,\n",
    "        \"gmvp\": {\n",
    "            \"weights\": w_gmvp,\n",
    "            \"return\": gmvp_return,\n",
    "            \"risk\": gmvp_std\n",
    "        },\n",
    "        \"mrr\": {\n",
    "            \"weights\": w_tan,\n",
    "            \"return\": tan_return,\n",
    "            \"risk\": tan_std,\n",
    "            \"sharpe\": tan_sharpe\n",
    "        }\n",
    "    }\n",
    "    return results\n",
    "\n",
    "def optimized_portfolio_printer(results):\n",
    "    print(\"\\nMean returns:\")\n",
    "    print(results[\"mean_returns\"])\n",
    "    print(\"\\nStd deviation:\")\n",
    "    print(results[\"std_returns\"])\n",
    "    print(\"\\nGMVP weights:\")\n",
    "    print(results[\"gmvp\"][\"weights\"])\n",
    "    print(\"\\nGMVP return:\", results[\"gmvp\"][\"return\"])\n",
    "    print(\"GMVP risk:\", results[\"gmvp\"][\"risk\"])\n",
    "    print(\"\\nMRR weights:\")\n",
    "    print(results[\"mrr\"][\"weights\"])\n",
    "    print(\"\\nMRR return:\", results[\"mrr\"][\"return\"])\n",
    "    print(\"MRR risk:\", results[\"mrr\"][\"risk\"])\n",
    "    print(\"MRR Sharpe:\", results[\"mrr\"][\"sharpe\"])\n",
    "\n",
    "def BRUTE_FORCE_find_best_portfolios_of_size_x(\n",
    "    filtered_df,\n",
    "    x,\n",
    "    risk_free_rate=0.0,\n",
    "    allow_short=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Try all combinations of size x.\n",
    "\n",
    "    INPUT:\n",
    "    filtered_df     : pandas DataFrame\n",
    "    x               : size of portfolio\n",
    "    risk_free_rate  : float\n",
    "\n",
    "    OUTPUT:\n",
    "    best_gmvp       : Best GMVP portfolio dictionary\n",
    "    best_mrr        : Best MRR portfolio dictionary\n",
    "\n",
    "    COMPLEXITY: O(n choose x) ~\n",
    "    n: company pool size\n",
    "    x: portfolio size\n",
    "    \"\"\"\n",
    "\n",
    "    companies = list(filtered_df.columns)\n",
    "    companies.remove(\"date\")\n",
    "    total_combinations = math.comb(len(companies), x)\n",
    "    best_gmvp = None\n",
    "    best_gmvp_risk = np.inf\n",
    "    best_mrr = None\n",
    "    best_mrr_sharpe = -np.inf\n",
    "    processed = 0\n",
    "    checked = 0\n",
    "    dropped = 0\n",
    "    print(f\"\\nTesting {len(companies)} choose {x} combinations...\")\n",
    "    for combo in itertools.combinations(companies, x):\n",
    "        processed += 1\n",
    "        sub_df = filter_dataset(filtered_df, company_codes=list(combo))\n",
    "        returns = compute_returns(sub_df)\n",
    "        if returns.shape[0] < 2 or returns.shape[1] < x: # ensure enough data\n",
    "          dropped += 1\n",
    "          continue\n",
    "        Sigma = np.cov(returns.values, rowvar=False) # compute covariance matrix\n",
    "        det = np.linalg.det(Sigma) # skip singular covariance matrix\n",
    "        if abs(det) < 1e-12:\n",
    "          dropped += 1\n",
    "          continue\n",
    "        checked += 1\n",
    "        results = portfolio_optimizer(returns, risk_free_rate, allow_short) # safe to optimize\n",
    "        gmvp_risk = results[\"gmvp\"][\"risk\"]\n",
    "        mrr_sharpe = results[\"mrr\"][\"sharpe\"]\n",
    "        # Track best GMVP\n",
    "        if gmvp_risk < best_gmvp_risk:\n",
    "            best_gmvp_risk = gmvp_risk\n",
    "            best_gmvp = {\n",
    "                \"companies\": combo,\n",
    "                \"gmvp\": results[\"gmvp\"],\n",
    "                \"mrr\": results[\"mrr\"]\n",
    "            }\n",
    "\n",
    "        # Track best MRR\n",
    "        if mrr_sharpe > best_mrr_sharpe:\n",
    "            best_mrr_sharpe = mrr_sharpe\n",
    "            best_mrr = {\n",
    "                \"companies\": combo,\n",
    "                \"gmvp\": results[\"gmvp\"],\n",
    "                \"mrr\": results[\"mrr\"]\n",
    "            }\n",
    "\n",
    "        if processed % 10000 == 0:\n",
    "            print(\n",
    "                f\"Processed {processed}/{total_combinations} | \"\n",
    "                f\"Checked {checked} | Dropped {dropped} | \"\n",
    "                f\"Best GMVP risk={best_gmvp_risk:.6f}, return={best_gmvp['gmvp']['return']:.6f} | \"\n",
    "                f\"Best MRR return={best_mrr['mrr']['return']:.6f}, risk={best_mrr['mrr']['risk']:.6f}\"\n",
    "            )\n",
    "    print(\"\\n===== FINAL SUMMARY =====\")\n",
    "    print(f\"Total combinations: {total_combinations}\")\n",
    "    print(f\"Processed: {processed}\")\n",
    "    print(f\"Valid (checked): {checked}\")\n",
    "    print(f\"Dropped: {dropped}\")\n",
    "    print(f\"Drop rate: {100*dropped/processed:.2f}%\")\n",
    "    return best_gmvp, best_mrr\n",
    "\n",
    "\n",
    "def BEAM_SEARCH_find_best_portfolios_of_size_x(\n",
    "    filtered_df,\n",
    "    x,\n",
    "    risk_free_rate=0.0,\n",
    "    allow_short=True,\n",
    "    beam_width=10,\n",
    "    random_samples=5000,\n",
    "    sharpe_filter_size=30,\n",
    "    corr_threshold=0.9 # stocks with corr > 0.9 cropped off\n",
    "):\n",
    "    \"\"\"\n",
    "    Greedy Heuristic\n",
    "    Step 1: Sharpe filter: Some stocks are clearly bad: Low return, High volatility, poor sharpe: Will never appear in an optimal portfolio\n",
    "            Modern portfolio theory tells us optimal portfolios lie in span of high-Sharpe assets. Low-Sharpe assets almost never contribute\n",
    "    Step 2: Correlation pruning: if two stocks are highly correlated, they move almost identically, owning both adds little diversification.\n",
    "    Step 3: Beam search: Instead of trying all combinations, grow portfolios step-by-step. At each step, keep only the best few candidates (=beam width)\n",
    "    Step 4: Random refinement: Beam search is is greedy -> it may miss some good combinations (local oprimization) -> Explore regions beam search may miss\n",
    "            Random sampling converges to global optimum as samples increase (Monte Carlo optimization principle)\n",
    "\n",
    "    COMPLEXITY: O(knx)\n",
    "    k: beam size\n",
    "    n: company pool size\n",
    "    x: portfolio size\n",
    "    \"\"\"\n",
    "\n",
    "    companies = list(filtered_df.columns)\n",
    "    companies.remove(\"date\")\n",
    "    print(\"\\n===== STEP 1: Sharpe filtering =====\")\n",
    "    base_returns = compute_returns(filtered_df)\n",
    "    mean = base_returns.mean()\n",
    "    std = base_returns.std()\n",
    "    sharpe = (mean - risk_free_rate) / std\n",
    "    sharpe = sharpe.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    sharpe_sorted = sharpe.sort_values(ascending=False)\n",
    "    filtered_companies = list(sharpe_sorted.head(sharpe_filter_size).index)\n",
    "    print(f\"Reduced from {len(companies)} to {len(filtered_companies)} stocks by Sharpe\")\n",
    "    print(\"\\n===== STEP 2: Correlation pruning =====\")\n",
    "    corr = base_returns[filtered_companies].corr().abs()\n",
    "    selected_uncorr = []\n",
    "    for stock in filtered_companies:\n",
    "        keep = True\n",
    "        for s in selected_uncorr:\n",
    "            if corr.loc[stock, s] > corr_threshold:\n",
    "                keep = False\n",
    "                break\n",
    "        if keep:\n",
    "            selected_uncorr.append(stock)\n",
    "    print(f\"Reduced to {len(selected_uncorr)} stocks after correlation pruning\")\n",
    "    search_space = selected_uncorr\n",
    "    total_combinations = math.comb(len(search_space), x) if len(search_space) >= x else 0\n",
    "    best_gmvp = None\n",
    "    best_gmvp_risk = np.inf\n",
    "    best_mrr = None\n",
    "    best_mrr_sharpe = -np.inf\n",
    "    processed = 0\n",
    "    checked = 0\n",
    "    dropped = 0\n",
    "    print(f\"\\nTesting heuristic search over reduced space...\")\n",
    "    print(\"\\n===== STEP 3: Beam search =====\")\n",
    "    beam = [([], None)]\n",
    "    for depth in range(x):\n",
    "        candidates = []\n",
    "        for combo, _ in beam:\n",
    "            for stock in search_space:\n",
    "                if stock in combo:\n",
    "                    continue\n",
    "                new_combo = combo + [stock]\n",
    "                sub_df = filter_dataset(filtered_df, company_codes=new_combo)\n",
    "                returns = compute_returns(sub_df)\n",
    "                if returns.shape[1] < len(new_combo):\n",
    "                    dropped += 1\n",
    "                    continue\n",
    "                Sigma = np.cov(returns.values, rowvar=False)\n",
    "                if np.ndim(Sigma) < 2:\n",
    "                    results = portfolio_optimizer(\n",
    "                        returns,\n",
    "                        risk_free_rate,\n",
    "                        allow_short\n",
    "                    )\n",
    "                else:\n",
    "                    if np.linalg.cond(Sigma) > 1e12:\n",
    "                        dropped += 1\n",
    "                        continue\n",
    "                    results = portfolio_optimizer(\n",
    "                        returns,\n",
    "                        risk_free_rate,\n",
    "                        allow_short\n",
    "                    )\n",
    "                sharpe_val = results[\"mrr\"][\"sharpe\"]\n",
    "                candidates.append((new_combo, sharpe_val, results))\n",
    "                processed += 1\n",
    "                checked += 1\n",
    "                gmvp_risk = results[\"gmvp\"][\"risk\"]\n",
    "                mrr_sharpe = results[\"mrr\"][\"sharpe\"]\n",
    "                # Track best GMVP\n",
    "                if gmvp_risk < best_gmvp_risk:\n",
    "                    best_gmvp_risk = gmvp_risk\n",
    "                    best_gmvp = {\n",
    "                        \"companies\": tuple(new_combo),\n",
    "                        \"gmvp\": results[\"gmvp\"],\n",
    "                        \"mrr\": results[\"mrr\"]\n",
    "                    }\n",
    "                # Track best MRR\n",
    "                if mrr_sharpe > best_mrr_sharpe:\n",
    "                    best_mrr_sharpe = mrr_sharpe\n",
    "                    best_mrr = {\n",
    "                        \"companies\": tuple(new_combo),\n",
    "                        \"gmvp\": results[\"gmvp\"],\n",
    "                        \"mrr\": results[\"mrr\"]\n",
    "                    }\n",
    "        candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "        beam = [(c[0], c[2]) for c in candidates[:beam_width]]\n",
    "        print(\n",
    "            f\"Depth {depth+1}/{x} | \"\n",
    "            f\"Processed {processed} | Checked {checked} | Dropped {dropped} | \"\n",
    "            f\"Best GMVP risk={best_gmvp_risk:.6f}, return={best_gmvp['gmvp']['return']:.6f} | \"\n",
    "            f\"Best MRR return={best_mrr['mrr']['return']:.6f}, risk={best_mrr['mrr']['risk']:.6f}\"\n",
    "        )\n",
    "    print(\"\\n===== STEP 4: Random refinement =====\")\n",
    "    for i in range(random_samples):\n",
    "        combo = tuple(np.random.choice(search_space, x, replace=True))\n",
    "        sub_df = filter_dataset(filtered_df, company_codes=list(combo))\n",
    "        returns = compute_returns(sub_df)\n",
    "        if returns.shape[1] < x:\n",
    "            dropped += 1\n",
    "            continue\n",
    "        Sigma = np.cov(returns.values, rowvar=False)\n",
    "        if np.ndim(Sigma) < 2:\n",
    "            results = portfolio_optimizer(\n",
    "                returns,\n",
    "                risk_free_rate,\n",
    "                allow_short\n",
    "            )\n",
    "        else:\n",
    "            if np.linalg.cond(Sigma) > 1e12:\n",
    "                dropped += 1\n",
    "                continue\n",
    "            results = portfolio_optimizer(\n",
    "                returns,\n",
    "                risk_free_rate,\n",
    "                allow_short\n",
    "            )\n",
    "        processed += 1\n",
    "        checked += 1\n",
    "        gmvp_risk = results[\"gmvp\"][\"risk\"]\n",
    "        mrr_sharpe = results[\"mrr\"][\"sharpe\"]\n",
    "\n",
    "        if gmvp_risk < best_gmvp_risk:\n",
    "            best_gmvp_risk = gmvp_risk\n",
    "            best_gmvp = {\n",
    "                \"companies\": combo,\n",
    "                \"gmvp\": results[\"gmvp\"],\n",
    "                \"mrr\": results[\"mrr\"]\n",
    "            }\n",
    "\n",
    "        if mrr_sharpe > best_mrr_sharpe:\n",
    "            best_mrr_sharpe = mrr_sharpe\n",
    "            best_mrr = {\n",
    "                \"companies\": combo,\n",
    "                \"gmvp\": results[\"gmvp\"],\n",
    "                \"mrr\": results[\"mrr\"]\n",
    "            }\n",
    "\n",
    "        if i % 1000 == 0 and i > 0:\n",
    "            print(\n",
    "                f\"Random {i}/{random_samples} | \"\n",
    "                f\"Processed {processed} | Checked {checked} | Dropped {dropped} | \"\n",
    "                f\"Best GMVP risk={best_gmvp_risk:.6f}, return={best_gmvp['gmvp']['return']:.6f} | \"\n",
    "                f\"Best MRR return={best_mrr['mrr']['return']:.6f}, risk={best_mrr['mrr']['risk']:.6f}\"\n",
    "            )\n",
    "    print(\"\\n===== FINAL SUMMARY =====\")\n",
    "    print(f\"Total combinations (original space): {total_combinations}\")\n",
    "    print(f\"Processed: {processed}\")\n",
    "    print(f\"Valid (checked): {checked}\")\n",
    "    print(f\"Dropped: {dropped}\")\n",
    "    if processed > 0:\n",
    "        print(f\"Drop rate: {100*dropped/processed:.2f}%\")\n",
    "    else:\n",
    "        print(\"Drop rate: 0%\")\n",
    "    return best_gmvp, best_mrr\n",
    "\n",
    "\n",
    "TRADING_DAYS = 252\n",
    "RISK_FREE_RATE = (1 + 0.0667)**(1/TRADING_DAYS) - 1\n",
    "def print_portfolio(title, portfolio):\n",
    "    if portfolio is None:\n",
    "        print(f\"\\n{title}: None\")\n",
    "        return\n",
    "    companies = portfolio[\"companies\"]\n",
    "    gmvp = portfolio[\"gmvp\"]\n",
    "    mrr = portfolio[\"mrr\"]\n",
    "    gmvp_return_daily = gmvp[\"return\"]\n",
    "    gmvp_risk_daily = gmvp[\"risk\"]\n",
    "    gmvp_return_annual = gmvp_return_daily * TRADING_DAYS\n",
    "    gmvp_risk_annual = gmvp_risk_daily * math.sqrt(TRADING_DAYS)\n",
    "    mrr_return_daily = mrr[\"return\"]\n",
    "    mrr_risk_daily = mrr[\"risk\"]\n",
    "    mrr_return_annual = mrr_return_daily * TRADING_DAYS\n",
    "    mrr_risk_annual = mrr_risk_daily * math.sqrt(TRADING_DAYS)\n",
    "    sharpe_daily = mrr[\"sharpe\"]\n",
    "    sharpe_annual = sharpe_daily * math.sqrt(TRADING_DAYS)\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"{title}\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nCompanies:\")\n",
    "    for c in companies:\n",
    "        print(f\"  {c}\")\n",
    "    print(\"\\nGMVP Portfolio Weights:\")\n",
    "    print(\"-\"*40)\n",
    "    for c, w in zip(companies, gmvp[\"weights\"]):\n",
    "        print(f\"{c:15s} : {w*100:8.3f} %\")\n",
    "    print(\"\\nGMVP Performance:\")\n",
    "    print(f\"  Daily Return  : {gmvp_return_daily*100:8.4f} %\")\n",
    "    print(f\"  Daily Risk    : {gmvp_risk_daily*100:8.4f} %\")\n",
    "    print(f\"  Annual Return : {gmvp_return_annual*100:8.2f} %\")\n",
    "    print(f\"  Annual Risk   : {gmvp_risk_annual*100:8.2f} %\")\n",
    "    print(\"\\nMRR Portfolio (Max Sharpe) Weights:\")\n",
    "    print(\"-\"*40)\n",
    "    for c, w in zip(companies, mrr[\"weights\"]):\n",
    "        print(f\"{c:15s} : {w*100:8.3f} %\")\n",
    "    print(\"\\nMRR Performance:\")\n",
    "    print(f\"  Daily Return  : {mrr_return_daily*100:8.4f} %\")\n",
    "    print(f\"  Daily Risk    : {mrr_risk_daily*100:8.4f} %\")\n",
    "    print(f\"  Annual Return : {mrr_return_annual*100:8.2f} %\")\n",
    "    print(f\"  Annual Risk   : {mrr_risk_annual*100:8.2f} %\")\n",
    "    print(f\"\\nSharpe Ratio:\")\n",
    "    print(f\"  Daily Sharpe  : {sharpe_daily:8.4f}\")\n",
    "    print(f\"  Annual Sharpe : {sharpe_annual:8.4f}\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "def symbol_exists_checker(available, symbols):\n",
    "    symbols_available = []\n",
    "    symbols_missing = []\n",
    "    for s in symbols:\n",
    "        if s in available:\n",
    "            symbols_available.append(s)\n",
    "        else:\n",
    "            symbols_missing.append(s)\n",
    "    print(\"Available:\", len(symbols_available))\n",
    "    print(\"Missing:\", len(symbols_missing))\n",
    "    print(\"\\nMissing symbols:\")\n",
    "    print(symbols_missing)\n",
    "    return symbols_available\n",
    "\n",
    "def export_both_portfolios_to_excel(\n",
    "    full_price_df,\n",
    "    best_gmvp,\n",
    "    best_mrr,\n",
    "    file_name=\"optimized_portfolios.xlsx\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Exports:\n",
    "    - Price table (date + portfolio stocks)\n",
    "    - Portfolio weights\n",
    "    - Performance metrics\n",
    "    Into same Excel sheet (results appended below price table)\n",
    "    \"\"\"\n",
    "    with pd.ExcelWriter(file_name, engine=\"xlsxwriter\") as writer:\n",
    "        # ================= GMVP =================\n",
    "        if best_gmvp is not None:\n",
    "            companies = list(best_gmvp[\"companies\"])\n",
    "            gmvp = best_gmvp[\"gmvp\"]\n",
    "            mrr = best_gmvp[\"mrr\"]\n",
    "            gmvp_df = full_price_df[[\"date\"] + companies].copy()\n",
    "            gmvp_df[\"date\"] = pd.to_datetime(gmvp_df[\"date\"])\n",
    "            gmvp_df = gmvp_df.sort_values(\"date\")\n",
    "            sheet_name = \"GMVP\"\n",
    "            gmvp_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "            worksheet = writer.sheets[sheet_name]\n",
    "            start_row = len(gmvp_df) + 3\n",
    "            # Write weights\n",
    "            worksheet.write(start_row, 0, \"GMVP Weights\")\n",
    "            for i, (c, w) in enumerate(zip(companies, gmvp[\"weights\"])):\n",
    "                worksheet.write(start_row + i + 1, 0, c)\n",
    "                worksheet.write(start_row + i + 1, 1, float(w))\n",
    "            # Performance metrics\n",
    "            gmvp_return_daily = gmvp[\"return\"]\n",
    "            gmvp_risk_daily = gmvp[\"risk\"]\n",
    "            gmvp_return_annual = gmvp_return_daily * TRADING_DAYS\n",
    "            gmvp_risk_annual = gmvp_risk_daily * np.sqrt(TRADING_DAYS)\n",
    "            metrics_row = start_row + len(companies) + 3\n",
    "            worksheet.write(metrics_row, 0, \"Performance Metrics\")\n",
    "            worksheet.write(metrics_row + 1, 0, \"Daily Return\")\n",
    "            worksheet.write(metrics_row + 1, 1, float(gmvp_return_daily))\n",
    "            worksheet.write(metrics_row + 2, 0, \"Daily Risk\")\n",
    "            worksheet.write(metrics_row + 2, 1, float(gmvp_risk_daily))\n",
    "            worksheet.write(metrics_row + 3, 0, \"Annual Return\")\n",
    "            worksheet.write(metrics_row + 3, 1, float(gmvp_return_annual))\n",
    "            worksheet.write(metrics_row + 4, 0, \"Annual Risk\")\n",
    "            worksheet.write(metrics_row + 4, 1, float(gmvp_risk_annual))\n",
    "        # ================= MRR =================\n",
    "        if best_mrr is not None:\n",
    "            companies = list(best_mrr[\"companies\"])\n",
    "            gmvp = best_mrr[\"gmvp\"]\n",
    "            mrr = best_mrr[\"mrr\"]\n",
    "            mrr_df = full_price_df[[\"date\"] + companies].copy()\n",
    "            mrr_df[\"date\"] = pd.to_datetime(mrr_df[\"date\"])\n",
    "            mrr_df = mrr_df.sort_values(\"date\")\n",
    "            sheet_name = \"MRR\"\n",
    "            mrr_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "            worksheet = writer.sheets[sheet_name]\n",
    "            start_row = len(mrr_df) + 3\n",
    "            # Write weights\n",
    "            worksheet.write(start_row, 0, \"MRR Weights\")\n",
    "            for i, (c, w) in enumerate(zip(companies, mrr[\"weights\"])):\n",
    "                worksheet.write(start_row + i + 1, 0, c)\n",
    "                worksheet.write(start_row + i + 1, 1, float(w))\n",
    "            # Performance metrics\n",
    "            mrr_return_daily = mrr[\"return\"]\n",
    "            mrr_risk_daily = mrr[\"risk\"]\n",
    "            mrr_return_annual = mrr_return_daily * TRADING_DAYS\n",
    "            mrr_risk_annual = mrr_risk_daily * np.sqrt(TRADING_DAYS)\n",
    "            sharpe_daily = mrr[\"sharpe\"]\n",
    "            sharpe_annual = sharpe_daily * np.sqrt(TRADING_DAYS)\n",
    "            metrics_row = start_row + len(companies) + 3\n",
    "            worksheet.write(metrics_row, 0, \"Performance Metrics\")\n",
    "            worksheet.write(metrics_row + 1, 0, \"Daily Return\")\n",
    "            worksheet.write(metrics_row + 1, 1, float(mrr_return_daily))\n",
    "            worksheet.write(metrics_row + 2, 0, \"Daily Risk\")\n",
    "            worksheet.write(metrics_row + 2, 1, float(mrr_risk_daily))\n",
    "            worksheet.write(metrics_row + 3, 0, \"Annual Return\")\n",
    "            worksheet.write(metrics_row + 3, 1, float(mrr_return_annual))\n",
    "            worksheet.write(metrics_row + 4, 0, \"Annual Risk\")\n",
    "            worksheet.write(metrics_row + 4, 1, float(mrr_risk_annual))\n",
    "            worksheet.write(metrics_row + 5, 0, \"Daily Sharpe\")\n",
    "            worksheet.write(metrics_row + 5, 1, float(sharpe_daily))\n",
    "            worksheet.write(metrics_row + 6, 0, \"Annual Sharpe\")\n",
    "            worksheet.write(metrics_row + 6, 1, float(sharpe_annual))\n",
    "    print(f\"\\nBoth portfolios with full results exported to: {file_name}\")\n",
    "\n",
    "def export_selected_companies_to_excel(\n",
    "    full_price_df,\n",
    "    company_keys,\n",
    "    file_name=\"selected_companies.xlsx\",\n",
    "    start_date=None,\n",
    "    end_date=None,\n",
    "    dropna=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Exports selected company stock prices to Excel in format:\n",
    "\n",
    "    date | Company1 | Company2 | ...\n",
    "\n",
    "    PARAMETERS:\n",
    "    full_price_df : loaded dataset\n",
    "    company_keys  : list of company symbols\n",
    "    file_name     : output Excel file name\n",
    "    start_date    : optional filter\n",
    "    end_date      : optional filter\n",
    "    dropna        : remove columns with NaNs\n",
    "    \"\"\"\n",
    "    if \"date\" not in full_price_df.columns:\n",
    "        raise ValueError(\"DataFrame must contain 'date' column\")\n",
    "    df = full_price_df.copy()\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    # Check which symbols exist\n",
    "    available = set(df.columns)\n",
    "    valid_companies = [c for c in company_keys if c in available]\n",
    "    missing = [c for c in company_keys if c not in available]\n",
    "    if missing:\n",
    "        print(\"Warning: These companies were not found:\")\n",
    "        print(missing)\n",
    "    if not valid_companies:\n",
    "        raise ValueError(\"None of the requested companies exist in dataset\")\n",
    "    # Select columns\n",
    "    df = df[[\"date\"] + valid_companies]\n",
    "    # Date filtering\n",
    "    if start_date:\n",
    "        df = df[df[\"date\"] >= pd.to_datetime(start_date)]\n",
    "    if end_date:\n",
    "        df = df[df[\"date\"] <= pd.to_datetime(end_date)]\n",
    "    df = df.sort_values(\"date\").reset_index(drop=True)\n",
    "    if dropna:\n",
    "        df = df.dropna(axis=1, how=\"any\")\n",
    "    # Export to Excel\n",
    "    df.to_excel(file_name, index=False)\n",
    "    print(f\"\\nExcel file created: {file_name}\")\n",
    "    print(f\"Columns exported: {['date'] + valid_companies}\")\n",
    "    print(f\"Total rows: {len(df)}\")\n",
    "\n",
    "def data_loading_pipeline_1():\n",
    "    file_id = \"1yJuY2SF3sCllibGXeyoNNzS6v2j7g08s\"\n",
    "    root = download_and_extract_google_drive_zip_1(file_id)\n",
    "    df = read_stock_data_from_folder(root)\n",
    "    print(df.head())\n",
    "\n",
    "    available = set(df.columns)\n",
    "    existing_codes = symbol_exists_checker(available, CHELSEA01); # NIFTY50_SYMBOLS\n",
    "    print(existing_codes)\n",
    "    filtered = filter_dataset(df, start_date=\"2018-01-01\") #company_codes=existing_codes)\n",
    "    print(filtered.head())\n",
    "    print(filtered[\"date\"].min())\n",
    "    print(filtered[\"date\"].max())\n",
    "    return filtered\n",
    "\n",
    "def data_loading_pipeline_2():\n",
    "    file_id = \"1edQni7obD5aQqfgqh_-bgz0NOOj6tXG7\"\n",
    "    root = download_and_extract_google_drive_zip_2(file_id)\n",
    "    df = read_bse_bhavcopy_folder(root)\n",
    "    #df = read_bse_bhavcopy_folder(root, strategy=\"top_turnover\", strategy_params={\"top_n\": 1000}) # Top n by turnover # CONFIGURE HERE\n",
    "    #df = read_bse_bhavcopy_folder(root, strategy=\"top_turnover\", strategy_params={\"top_n\": 120}) # Random n\n",
    "    #df = read_bse_bhavcopy_folder(root, strategy=\"price_filter\", strategy_params={\"min_price\": 100}) # Price filter to remove penny stocks\n",
    "    #df = read_bse_bhavcopy_folder(root, strategy=\"turnover_price\", strategy_params={\"top_n\": 150, \"min_price\": 75})\n",
    "\n",
    "    available = set(df.columns)\n",
    "    existing_codes = symbol_exists_checker(available, CHELSEA01)  # CONFIGURE HERE\n",
    "\n",
    "    filtered = filter_dataset(\n",
    "      df,\n",
    "      start_date=\"2024-08-01\",\n",
    "      company_codes=existing_codes # CONFIGURE HERE\n",
    "    )\n",
    "\n",
    "    print(filtered.head())\n",
    "    print(filtered[\"date\"].min())\n",
    "    print(filtered[\"date\"].max())\n",
    "    return filtered\n",
    "\n",
    "def main():\n",
    "\n",
    "    # data = data_loading_pipeline_1() # for older dataset\n",
    "    data = data_loading_pipeline_2() # for newer dataset\n",
    "\n",
    "    #best_gmvp, best_mrr = BRUTE_FORCE_find_best_portfolios_of_size_x(data, x=3, risk_free_rate=RISK_FREE_RATE, allow_short=False)\n",
    "    best_gmvp, best_mrr = BEAM_SEARCH_find_best_portfolios_of_size_x(data, x=10, risk_free_rate=RISK_FREE_RATE, allow_short=False) # CONFIGURE HERE\n",
    "\n",
    "    print_portfolio(\"BEST GMVP PORTFOLIO\", best_gmvp)\n",
    "    print_portfolio(\"BEST MRR PORTFOLIO\", best_mrr)\n",
    "    # export_both_portfolios_to_excel(data, best_gmvp, best_mrr)\n",
    "\n",
    "    export_selected_companies_to_excel(\n",
    "      data,\n",
    "      #[\"VAGHANI\", \"RRP\", \"EUROASIA\", \"MIDWEST\", \"GLITTEKG\", \"IMEC\"],\n",
    "      UTKARSH_TICKERS,\n",
    "      file_name=\"best_mrr3.xlsx\",\n",
    "      start_date=\"2024-08-01\"\n",
    "    )\n",
    "\n",
    "    # data = {\n",
    "    #     \"date\": [\n",
    "    #         \"2020-01\",\n",
    "    #         \"2020-02\",\n",
    "    #         \"2020-03\",\n",
    "    #         \"2020-04\",\n",
    "    #         \"2020-05\",\n",
    "    #         \"2020-06\"\n",
    "    #     ],\n",
    "    #     \"AAPL\": [100, 105, 110, 108, 115, 120],\n",
    "    #     \"MSFT\": [200, 210, 220, 215, 225, 230],\n",
    "    #     \"GOOG\": [300, 295, 310, 320, 330, 340],\n",
    "    #     \"AMZN\": [400, 420, 430, 440, 450, 460]\n",
    "    # }\n",
    "\n",
    "    # df = pd.DataFrame(data)\n",
    "    # print(\"\\nOriginal dataset:\")\n",
    "    # print(df)\n",
    "\n",
    "    # filtered = filter_dataset(df, start_date=\"2020-02\", end_date=\"2020-06\", company_codes=[\"AAPL\", \"MSFT\", \"GOOG\"])\n",
    "    # print(\"\\nFiltered dataset:\\n\", filtered)\n",
    "\n",
    "    # returns = compute_returns(filtered)\n",
    "    # print(\"\\nReturns:\\n\", returns)\n",
    "\n",
    "    # results = portfolio_optimizer(returns, risk_free_rate=0.01)\n",
    "    # optimized_portfolio_printer(results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTOR MAP\n",
    "# ============================================================\n",
    "\n",
    "SECTOR_MAP: dict[str, str] = {\n",
    "    # Defense\n",
    "    \"BEL\": \"Defense\", \"HAL\": \"Defense\", \"GRSE\": \"Defense\", \"COCHINSHIP\": \"Defense\",\n",
    "    # Banking\n",
    "    \"SBIN\": \"Banking\", \"HDFCBANK\": \"Banking\", \"ICICIBANK\": \"Banking\",\n",
    "    \"AXISBANK\": \"Banking\", \"KOTAKBANK\": \"Banking\", \"INDUSINDBK\": \"Banking\",\n",
    "    \"BANKBARODA\": \"Banking\", \"UNIONBANK\": \"Banking\", \"BANKINDIA\": \"Banking\",\n",
    "    \"DCBBANK\": \"Banking\", \"KARURVYSYA\": \"Banking\", \"CUB\": \"Banking\",\n",
    "    # IT\n",
    "    \"TCS\": \"IT\", \"INFY\": \"IT\", \"WIPRO\": \"IT\", \"HCLTECH\": \"IT\", \"TECHM\": \"IT\",\n",
    "    \"LTIM\": \"IT\", \"NETWEB\": \"IT\",\n",
    "    # Oil & Gas\n",
    "    \"RELIANCE\": \"OilGas\", \"ONGC\": \"OilGas\", \"BPCL\": \"OilGas\", \"MRPL\": \"OilGas\",\n",
    "    # Pharma\n",
    "    \"SUNPHARMA\": \"Pharma\", \"DRREDDY\": \"Pharma\", \"CIPLA\": \"Pharma\",\n",
    "    \"DIVISLAB\": \"Pharma\", \"APOLLOHOSP\": \"Pharma\",\n",
    "    # Auto\n",
    "    \"MARUTI\": \"Auto\", \"TATAMOTORS\": \"Auto\", \"BAJAJ-AUTO\": \"Auto\",\n",
    "    \"EICHERMOT\": \"Auto\", \"HEROMOTOCO\": \"Auto\", \"M&M\": \"Auto\",\n",
    "    # FMCG\n",
    "    \"HINDUNILVR\": \"FMCG\", \"ITC\": \"FMCG\", \"BRITANNIA\": \"FMCG\",\n",
    "    \"DABUR\": \"FMCG\", \"NESTLEIND\": \"FMCG\", \"TATACONSUM\": \"FMCG\",\n",
    "    # Finance (NBFC)\n",
    "    \"BAJFINANCE\": \"Finance\", \"BAJAJFINSV\": \"Finance\", \"SBILIFE\": \"Finance\",\n",
    "    \"HDFCLIFE\": \"Finance\", \"LTF\": \"Finance\", \"TFCILTD\": \"Finance\",\n",
    "    # Metals & Mining\n",
    "    \"TATASTEEL\": \"Metals\", \"HINDALCO\": \"Metals\", \"JSWSTEEL\": \"Metals\",\n",
    "    \"COALINDIA\": \"Metals\", \"ADANIENT\": \"Metals\",\n",
    "    # Power & Utilities\n",
    "    \"POWERGRID\": \"Power\", \"NTPC\": \"Power\", \"BGRENERGY\": \"Power\",\n",
    "    # Infrastructure\n",
    "    \"LT\": \"Infrastructure\", \"ADANIPORTS\": \"Infrastructure\", \"ABINFRA\": \"Infrastructure\",\n",
    "    # Commodities\n",
    "    \"ASIANPAINT\": \"Commodities\", \"ULTRACEMCO\": \"Commodities\", \"GRASIM\": \"Commodities\",\n",
    "}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MULTI-FACTOR STOCK SELECTION ENGINE\n",
    "# ============================================================\n",
    "\n",
    "def multi_factor_stock_selector(\n",
    "    price_df: pd.DataFrame,\n",
    "    top_n: int = 50,\n",
    "    weights: dict | None = None\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    Ranks stocks using multiple factors and returns the top N.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    price_df : pd.DataFrame\n",
    "        DataFrame with 'date' column and stock price columns.\n",
    "    top_n : int\n",
    "        Number of top stocks to return.\n",
    "    weights : dict or None\n",
    "        Factor weights with keys: 'momentum', 'low_volatility',\n",
    "        'sharpe', 'sortino', 'max_drawdown'.\n",
    "        Defaults to equal weights (0.2 each).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[str]\n",
    "        Symbols of top N stocks ranked by composite score.\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = {\n",
    "            \"momentum\": 0.2,\n",
    "            \"low_volatility\": 0.2,\n",
    "            \"sharpe\": 0.2,\n",
    "            \"sortino\": 0.2,\n",
    "            \"max_drawdown\": 0.2,\n",
    "        }\n",
    "    prices = price_df.copy()\n",
    "    prices.set_index(\"date\", inplace=True)\n",
    "    prices.index = pd.to_datetime(prices.index)\n",
    "    prices = prices.dropna(axis=1, how=\"any\")\n",
    "    returns = prices.pct_change().dropna()\n",
    "    if returns.empty or returns.shape[1] == 0:\n",
    "        return []\n",
    "\n",
    "    # Factor 1: Momentum (cumulative return over the period)\n",
    "    momentum = (1 + returns).prod() - 1\n",
    "\n",
    "    # Factor 2: Low Volatility (lower std is better — negated in scoring)\n",
    "    volatility = returns.std()\n",
    "\n",
    "    # Factor 3: Sharpe Ratio\n",
    "    mean_ret = returns.mean()\n",
    "    sharpe = mean_ret / volatility\n",
    "\n",
    "    # Factor 4: Sortino Ratio (downside risk-adjusted return)\n",
    "    downside_std = returns.clip(upper=0).std()\n",
    "    sortino = mean_ret / downside_std.replace(0, np.nan)\n",
    "\n",
    "    # Factor 5: Maximum Drawdown (less negative is better — negated in scoring)\n",
    "    cumulative = (1 + returns).cumprod()\n",
    "    rolling_max = cumulative.cummax()\n",
    "    max_drawdown = ((cumulative - rolling_max) / rolling_max).min()\n",
    "\n",
    "    def zscore(series: pd.Series) -> pd.Series:\n",
    "        std = series.std()\n",
    "        if std == 0:\n",
    "            return series * 0\n",
    "        return (series - series.mean()) / std\n",
    "\n",
    "    composite_score = (\n",
    "        weights[\"momentum\"] * zscore(momentum)\n",
    "        + weights[\"low_volatility\"] * zscore(-volatility)\n",
    "        + weights[\"sharpe\"] * zscore(sharpe)\n",
    "        + weights[\"sortino\"] * zscore(sortino.fillna(0))\n",
    "        + weights[\"max_drawdown\"] * zscore(-max_drawdown)\n",
    "    )\n",
    "    return composite_score.nlargest(top_n).index.tolist()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# SECTOR DIVERSIFICATION CONSTRAINT\n",
    "# ============================================================\n",
    "\n",
    "def sector_diversified_selection(\n",
    "    symbols: list[str],\n",
    "    sector_map: dict[str, str],\n",
    "    max_per_sector: int = 3\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    Filters a ranked list of symbols to ensure sector diversification.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    symbols : list[str]\n",
    "        Ordered list of stock symbols (highest-ranked first).\n",
    "    sector_map : dict[str, str]\n",
    "        Mapping from symbol to sector name (e.g., SECTOR_MAP).\n",
    "    max_per_sector : int\n",
    "        Maximum number of stocks allowed per sector.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[str]\n",
    "        Subset of symbols with at most max_per_sector per sector.\n",
    "    \"\"\"\n",
    "    sector_count: dict[str, int] = {}\n",
    "    selected: list[str] = []\n",
    "    for symbol in symbols:\n",
    "        sector = sector_map.get(symbol, \"Unknown\")\n",
    "        count = sector_count.get(sector, 0)\n",
    "        if count < max_per_sector:\n",
    "            selected.append(symbol)\n",
    "            sector_count[sector] = count + 1\n",
    "    return selected\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MARKET REGIME DETECTION\n",
    "# ============================================================\n",
    "\n",
    "def detect_market_regime(\n",
    "    price_df: pd.DataFrame,\n",
    "    index_col: str | None = None,\n",
    "    short_window: int = 50,\n",
    "    long_window: int = 200\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Classifies the market as BULL, BEAR, or SIDEWAYS using moving averages.\n",
    "\n",
    "    If the short MA is more than 2% above the long MA → BULL.\n",
    "    If the short MA is more than 2% below the long MA → BEAR.\n",
    "    Otherwise → SIDEWAYS.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    price_df : pd.DataFrame\n",
    "        Price DataFrame with 'date' column and stock price columns.\n",
    "    index_col : str or None\n",
    "        Column to use as the market index. Uses the first stock column if None.\n",
    "    short_window : int\n",
    "        Short moving average window in trading days.\n",
    "    long_window : int\n",
    "        Long moving average window in trading days.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        'BULL', 'BEAR', or 'SIDEWAYS'.\n",
    "    \"\"\"\n",
    "    prices = price_df.copy()\n",
    "    prices.set_index(\"date\", inplace=True)\n",
    "    prices.index = pd.to_datetime(prices.index)\n",
    "    if index_col is not None and index_col in prices.columns:\n",
    "        series = prices[index_col].dropna()\n",
    "    else:\n",
    "        series = prices.iloc[:, 0].dropna()\n",
    "    if len(series) < long_window:\n",
    "        return \"SIDEWAYS\"\n",
    "    short_ma = series.rolling(window=short_window).mean()\n",
    "    long_ma = series.rolling(window=long_window).mean()\n",
    "    last_short = short_ma.iloc[-1]\n",
    "    last_long = long_ma.iloc[-1]\n",
    "    if pd.isna(last_short) or pd.isna(last_long) or last_long == 0:\n",
    "        return \"SIDEWAYS\"\n",
    "    ratio = (last_short - last_long) / last_long\n",
    "    if ratio > 0.02:\n",
    "        return \"BULL\"\n",
    "    elif ratio < -0.02:\n",
    "        return \"BEAR\"\n",
    "    return \"SIDEWAYS\"\n",
    "\n",
    "\n",
    "def regime_adjusted_weights(regime: str) -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Returns multi-factor weights tuned for the detected market regime.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    regime : str\n",
    "        Market regime string: 'BULL', 'BEAR', or 'SIDEWAYS'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, float]\n",
    "        Weight dictionary compatible with multi_factor_stock_selector.\n",
    "    \"\"\"\n",
    "    if regime == \"BULL\":\n",
    "        return {\n",
    "            \"momentum\": 0.35,\n",
    "            \"low_volatility\": 0.10,\n",
    "            \"sharpe\": 0.25,\n",
    "            \"sortino\": 0.20,\n",
    "            \"max_drawdown\": 0.10,\n",
    "        }\n",
    "    elif regime == \"BEAR\":\n",
    "        return {\n",
    "            \"momentum\": 0.05,\n",
    "            \"low_volatility\": 0.35,\n",
    "            \"sharpe\": 0.20,\n",
    "            \"sortino\": 0.15,\n",
    "            \"max_drawdown\": 0.25,\n",
    "        }\n",
    "    # SIDEWAYS\n",
    "    return {\n",
    "        \"momentum\": 0.20,\n",
    "        \"low_volatility\": 0.20,\n",
    "        \"sharpe\": 0.25,\n",
    "        \"sortino\": 0.20,\n",
    "        \"max_drawdown\": 0.15,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# GENETIC ALGORITHM PORTFOLIO OPTIMIZER\n",
    "# ============================================================\n",
    "\n",
    "def genetic_algorithm_portfolio_search(\n",
    "    filtered_df: pd.DataFrame,\n",
    "    x: int,\n",
    "    risk_free_rate: float = 0.0,\n",
    "    allow_short: bool = True,\n",
    "    population_size: int = 50,\n",
    "    generations: int = 30,\n",
    "    mutation_rate: float = 0.1,\n",
    "    elite_size: int = 5\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Genetic Algorithm portfolio optimizer.\n",
    "\n",
    "    Uses stock combinations as chromosomes. Fitness function is Sharpe ratio\n",
    "    (for MRR) and negative risk (for GMVP). Applies crossover and mutation\n",
    "    operators across generations.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filtered_df : pd.DataFrame\n",
    "        Price DataFrame with 'date' column and stock price columns.\n",
    "    x : int\n",
    "        Portfolio size (number of stocks per chromosome).\n",
    "    risk_free_rate : float\n",
    "        Daily risk-free rate used in Sharpe calculation.\n",
    "    allow_short : bool\n",
    "        Whether to allow short selling.\n",
    "    population_size : int\n",
    "        Number of chromosomes per generation.\n",
    "    generations : int\n",
    "        Number of generations to evolve.\n",
    "    mutation_rate : float\n",
    "        Probability of mutating one gene per chromosome after crossover.\n",
    "    elite_size : int\n",
    "        Number of best chromosomes preserved unchanged each generation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (best_gmvp, best_mrr) portfolio dictionaries.\n",
    "    \"\"\"\n",
    "    companies = list(filtered_df.columns)\n",
    "    companies.remove(\"date\")\n",
    "    if len(companies) < x:\n",
    "        raise ValueError(f\"Need at least {x} companies, got {len(companies)}\")\n",
    "\n",
    "    def _evaluate(combo: tuple) -> tuple:\n",
    "        \"\"\"Returns (gmvp_risk, mrr_sharpe, results_or_None).\"\"\"\n",
    "        sub_df = filter_dataset(filtered_df, company_codes=list(combo))\n",
    "        returns = compute_returns(sub_df)\n",
    "        if returns.shape[1] < x:\n",
    "            return np.inf, -np.inf, None\n",
    "        Sigma = np.cov(returns.values, rowvar=False)\n",
    "        if np.ndim(Sigma) >= 2 and np.linalg.cond(Sigma) > 1e12:\n",
    "            return np.inf, -np.inf, None\n",
    "        results = portfolio_optimizer(returns, risk_free_rate, allow_short)\n",
    "        return results[\"gmvp\"][\"risk\"], results[\"mrr\"][\"sharpe\"], results\n",
    "\n",
    "    # Initialise population with random unique-stock combinations\n",
    "    population = [\n",
    "        tuple(np.random.choice(companies, x, replace=False))\n",
    "        for _ in range(population_size)\n",
    "    ]\n",
    "\n",
    "    best_gmvp = None\n",
    "    best_gmvp_risk = np.inf\n",
    "    best_mrr = None\n",
    "    best_mrr_sharpe = -np.inf\n",
    "\n",
    "    print(f\"\\n===== Genetic Algorithm: {generations} generations, population={population_size} =====\")\n",
    "    for gen in range(generations):\n",
    "        fitness_list = []\n",
    "        for chrom in population:\n",
    "            gf, mf, res = _evaluate(chrom)\n",
    "            fitness_list.append((chrom, gf, mf, res))\n",
    "            if res is not None:\n",
    "                if gf < best_gmvp_risk:\n",
    "                    best_gmvp_risk = gf\n",
    "                    best_gmvp = {\"companies\": chrom, \"gmvp\": res[\"gmvp\"], \"mrr\": res[\"mrr\"]}\n",
    "                if mf > best_mrr_sharpe:\n",
    "                    best_mrr_sharpe = mf\n",
    "                    best_mrr = {\"companies\": chrom, \"gmvp\": res[\"gmvp\"], \"mrr\": res[\"mrr\"]}\n",
    "\n",
    "        # Sort by MRR Sharpe (descending) for selection\n",
    "        fitness_list.sort(key=lambda t: t[2], reverse=True)\n",
    "        print(\n",
    "            f\"Gen {gen + 1}/{generations} | \"\n",
    "            f\"Best GMVP risk={best_gmvp_risk:.6f} | \"\n",
    "            f\"Best MRR Sharpe={best_mrr_sharpe:.6f}\"\n",
    "        )\n",
    "\n",
    "        # Elitism: top chromosomes pass unchanged\n",
    "        new_population = [t[0] for t in fitness_list[:elite_size]]\n",
    "\n",
    "        # Selection pool: top half of population\n",
    "        pool = [t[0] for t in fitness_list[:max(population_size // 2, elite_size)]]\n",
    "\n",
    "        # Crossover + Mutation to fill remainder of population\n",
    "        while len(new_population) < population_size:\n",
    "            p1 = pool[np.random.randint(len(pool))]\n",
    "            p2 = pool[np.random.randint(len(pool))]\n",
    "            # Crossover: merge p1 and p2 genes, trim to size x\n",
    "            child: list[str] = list(p1)\n",
    "            for gene in p2:\n",
    "                if gene not in child:\n",
    "                    child.append(gene)\n",
    "            if len(child) < x:\n",
    "                remaining = [c for c in companies if c not in child]\n",
    "                np.random.shuffle(remaining)\n",
    "                child += remaining[:x - len(child)]\n",
    "            child = child[:x]\n",
    "            # Mutation: randomly replace one gene\n",
    "            if np.random.random() < mutation_rate:\n",
    "                idx = np.random.randint(x)\n",
    "                candidates = [c for c in companies if c not in child]\n",
    "                if candidates:\n",
    "                    child[idx] = np.random.choice(candidates)\n",
    "            new_population.append(tuple(child))\n",
    "\n",
    "        population = new_population\n",
    "\n",
    "    print(\"\\n===== GA Complete =====\")\n",
    "    print(f\"Best GMVP risk: {best_gmvp_risk:.6f}\")\n",
    "    print(f\"Best MRR Sharpe: {best_mrr_sharpe:.6f}\")\n",
    "    return best_gmvp, best_mrr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# RISK PARITY PORTFOLIO\n",
    "# ============================================================\n",
    "\n",
    "def risk_parity_portfolio(returns_df: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Calculates a risk parity portfolio where each asset contributes\n",
    "    equally to total portfolio risk.\n",
    "\n",
    "    Uses scipy.optimize.minimize with the SLSQP method under long-only\n",
    "    and full-investment constraints.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    returns_df : pd.DataFrame\n",
    "        Returns DataFrame with assets as columns and time as rows.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary with keys 'weights' (np.ndarray), 'return' (float),\n",
    "        and 'risk' (float).\n",
    "    \"\"\"\n",
    "    returns = returns_df.values\n",
    "    n = returns.shape[1]\n",
    "    Sigma = np.cov(returns, rowvar=False)\n",
    "\n",
    "    if n == 1:\n",
    "        return {\n",
    "            \"weights\": np.array([1.0]),\n",
    "            \"return\": float(returns.mean()),\n",
    "            \"risk\": float(returns.std()),\n",
    "        }\n",
    "\n",
    "    def _risk_contributions(w: np.ndarray) -> np.ndarray:\n",
    "        portfolio_var = float(w @ Sigma @ w)\n",
    "        if portfolio_var <= 0:\n",
    "            return np.zeros(n)\n",
    "        return w * (Sigma @ w) / portfolio_var\n",
    "\n",
    "    def _objective(w: np.ndarray) -> float:\n",
    "        rc = _risk_contributions(w)\n",
    "        target = 1.0 / n\n",
    "        return float(np.sum((rc - target) ** 2))\n",
    "\n",
    "    constraints = [{\"type\": \"eq\", \"fun\": lambda w: np.sum(w) - 1.0}]\n",
    "    bounds = [(0.0, 1.0)] * n\n",
    "    w0 = np.ones(n) / n\n",
    "\n",
    "    result = minimize(\n",
    "        _objective,\n",
    "        w0,\n",
    "        method=\"SLSQP\",\n",
    "        bounds=bounds,\n",
    "        constraints=constraints,\n",
    "        options={\"ftol\": 1e-10, \"maxiter\": 500},\n",
    "    )\n",
    "\n",
    "    weights = np.maximum(result.x, 0)\n",
    "    weights /= weights.sum()\n",
    "    mu = np.mean(returns, axis=0)\n",
    "    port_return = float(weights @ mu)\n",
    "    port_risk = float(np.sqrt(weights @ Sigma @ weights))\n",
    "    return {\"weights\": weights, \"return\": port_return, \"risk\": port_risk}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# VISUALIZATION UTILITIES\n",
    "# ============================================================\n",
    "\n",
    "def plot_efficient_frontier(\n",
    "    returns_df: pd.DataFrame,\n",
    "    n_portfolios: int = 3000,\n",
    "    risk_free_rate: float = 0.0,\n",
    "    title: str = \"Efficient Frontier\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plots the efficient frontier by simulating random long-only portfolios.\n",
    "\n",
    "    Each simulated portfolio is coloured by its annualised Sharpe ratio.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    returns_df : pd.DataFrame\n",
    "        Returns DataFrame with assets as columns and time as rows.\n",
    "    n_portfolios : int\n",
    "        Number of random portfolios to simulate.\n",
    "    risk_free_rate : float\n",
    "        Daily risk-free rate for Sharpe ratio calculation.\n",
    "    title : str\n",
    "        Title displayed on the chart.\n",
    "    \"\"\"\n",
    "    returns = returns_df.values\n",
    "    n = returns.shape[1]\n",
    "    mu = np.mean(returns, axis=0)\n",
    "    Sigma = np.cov(returns, rowvar=False)\n",
    "\n",
    "    port_returns = []\n",
    "    port_risks = []\n",
    "    port_sharpes = []\n",
    "    for _ in range(n_portfolios):\n",
    "        w = np.random.dirichlet(np.ones(n))\n",
    "        r = float(w @ mu)\n",
    "        risk = float(np.sqrt(w @ Sigma @ w))\n",
    "        sharpe = (r - risk_free_rate) / risk if risk > 0 else 0.0\n",
    "        port_returns.append(r)\n",
    "        port_risks.append(risk)\n",
    "        port_sharpes.append(sharpe)\n",
    "\n",
    "    port_returns = np.array(port_returns)\n",
    "    port_risks = np.array(port_risks)\n",
    "    port_sharpes = np.array(port_sharpes)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sc = plt.scatter(\n",
    "        port_risks * np.sqrt(TRADING_DAYS) * 100,\n",
    "        port_returns * TRADING_DAYS * 100,\n",
    "        c=port_sharpes * np.sqrt(TRADING_DAYS),\n",
    "        cmap=\"viridis\",\n",
    "        alpha=0.5,\n",
    "        s=10,\n",
    "    )\n",
    "    plt.colorbar(sc, label=\"Annual Sharpe Ratio\")\n",
    "    plt.xlabel(\"Annual Risk (%)\")\n",
    "    plt.ylabel(\"Annual Return (%)\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_portfolio_weights(\n",
    "    portfolio: dict,\n",
    "    title: str = \"Portfolio Allocation\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plots a grouped bar chart of GMVP and MRR weights for a portfolio.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    portfolio : dict\n",
    "        Portfolio dictionary with 'companies', 'gmvp', and 'mrr' keys\n",
    "        (as returned by BEAM_SEARCH_find_best_portfolios_of_size_x,\n",
    "        genetic_algorithm_portfolio_search, etc.).\n",
    "    title : str\n",
    "        Title displayed on the chart.\n",
    "    \"\"\"\n",
    "    companies = list(portfolio[\"companies\"])\n",
    "    gmvp_weights = portfolio[\"gmvp\"][\"weights\"]\n",
    "    mrr_weights = portfolio[\"mrr\"][\"weights\"]\n",
    "\n",
    "    x = np.arange(len(companies))\n",
    "    width = 0.35\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(min(max(8, len(companies)), 20), 5))\n",
    "    ax.bar(x - width / 2, gmvp_weights * 100, width, label=\"GMVP\", color=\"steelblue\")\n",
    "    ax.bar(x + width / 2, mrr_weights * 100, width, label=\"MRR (Max Sharpe)\", color=\"darkorange\")\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(companies, rotation=45, ha=\"right\")\n",
    "    ax.set_ylabel(\"Weight (%)\")\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    ax.axhline(0, color=\"black\", linewidth=0.8)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EXAMPLE USAGE OF NEW FEATURES\n",
    "# ============================================================\n",
    "\n",
    "# --- Multi-Factor Selection (regime-aware) ---\n",
    "# regime = detect_market_regime(data)                          # e.g. 'BULL'\n",
    "# factor_weights = regime_adjusted_weights(regime)\n",
    "# top_stocks = multi_factor_stock_selector(data, top_n=50, weights=factor_weights)\n",
    "# diversified = sector_diversified_selection(top_stocks, SECTOR_MAP, max_per_sector=3)\n",
    "# print(f\"Regime: {regime}\")\n",
    "# print(f\"Selected {len(diversified)} sector-diversified stocks:\", diversified)\n",
    "\n",
    "# --- Genetic Algorithm Optimizer ---\n",
    "# filtered = filter_dataset(data, start_date=\"2024-08-01\", company_codes=diversified)\n",
    "# best_gmvp_ga, best_mrr_ga = genetic_algorithm_portfolio_search(\n",
    "#     filtered, x=5, risk_free_rate=RISK_FREE_RATE, allow_short=False,\n",
    "#     population_size=40, generations=20, mutation_rate=0.15\n",
    "# )\n",
    "# print_portfolio(\"GA BEST GMVP\", best_gmvp_ga)\n",
    "# print_portfolio(\"GA BEST MRR\",  best_mrr_ga)\n",
    "\n",
    "# --- Risk Parity Portfolio ---\n",
    "# some_stocks = [\"SBIN\", \"TCS\", \"RELIANCE\", \"HDFCBANK\", \"INFY\"]\n",
    "# filtered_rp = filter_dataset(data, company_codes=some_stocks)\n",
    "# returns_rp  = compute_returns(filtered_rp)\n",
    "# rp = risk_parity_portfolio(returns_rp)\n",
    "# print(\"Risk Parity weights:\", dict(zip(some_stocks, rp[\"weights\"])))\n",
    "\n",
    "# --- Visualizations ---\n",
    "# filtered_vis = filter_dataset(data, company_codes=some_stocks)\n",
    "# returns_vis  = compute_returns(filtered_vis)\n",
    "# plot_efficient_frontier(returns_vis, n_portfolios=2000, risk_free_rate=RISK_FREE_RATE)\n",
    "# if best_gmvp_ga is not None:\n",
    "#     plot_portfolio_weights(best_gmvp_ga, title=\"GA GMVP Portfolio Weights\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
