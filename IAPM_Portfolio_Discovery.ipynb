{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "collapsed": true,
        "id": "_VfbYKziimKT",
        "outputId": "fa7a4bfa-2f7b-4554-93ed-a2dff885b6a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nIAPM Portfolio discovery\\nBharath, Chelsea, Gaurav, Vikram, Utkarsh, Yash\\n\\n2009-2021 dataset link: https://drive.google.com/file/d/1yJuY2SF3sCllibGXeyoNNzS6v2j7g08s/view?usp=sharing\\n01/08/24-31/12/25 dataset link: https://drive.google.com/file/d/17DOkvtHBUXqDMvnWVTku1TfRFNEKolS7/view?usp=sharing\\n01/08/24-25/02/26 dataset link: https://drive.google.com/file/d/1edQni7obD5aQqfgqh_-bgz0NOOj6tXG7/view?usp=sharing\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "'''\n",
        "IAPM Portfolio discovery\n",
        "Bharath, Chelsea, Gaurav, Vikram, Utkarsh, Yash\n",
        "\n",
        "2009-2021 dataset link: https://drive.google.com/file/d/1yJuY2SF3sCllibGXeyoNNzS6v2j7g08s/view?usp=sharing\n",
        "01/08/24-31/12/25 dataset link: https://drive.google.com/file/d/17DOkvtHBUXqDMvnWVTku1TfRFNEKolS7/view?usp=sharing\n",
        "01/08/24-25/02/26 dataset link: https://drive.google.com/file/d/1edQni7obD5aQqfgqh_-bgz0NOOj6tXG7/view?usp=sharing\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "import zipfile\n",
        "import requests\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gdown\n",
        "import glob\n",
        "import math\n",
        "\n",
        "NIFTY50_SYMBOLS = [\n",
        "    \"ADANIENT\", \"ADANIPORTS\", \"APOLLOHOSP\", \"ASIANPAINT\", \"AXISBANK\",\n",
        "    \"BAJAJ-AUTO\", \"BAJFINANCE\", \"BAJAJFINSV\", \"BPCL\", \"BHARTIARTL\",\n",
        "    \"BRITANNIA\", \"CIPLA\", \"COALINDIA\", \"DIVISLAB\", \"DRREDDY\",\n",
        "    \"EICHERMOT\", \"GRASIM\", \"HCLTECH\", \"HDFCBANK\", \"HDFCLIFE\",\n",
        "    \"HEROMOTOCO\", \"HINDALCO\", \"HINDUNILVR\", \"ICICIBANK\", \"ITC\",\n",
        "    \"INDUSINDBK\", \"INFY\", \"JSWSTEEL\", \"KOTAKBANK\", \"LT\",\n",
        "    \"LTIM\", \"M&M\", \"MARUTI\", \"NTPC\", \"NESTLEIND\",\n",
        "    \"ONGC\", \"POWERGRID\", \"RELIANCE\", \"SBILIFE\", \"SBIN\",\n",
        "    \"SUNPHARMA\", \"TCS\", \"TATACONSUM\", \"TATAMOTORS\", \"TATASTEEL\",\n",
        "    \"TECHM\", \"TITAN\", \"ULTRACEMCO\", \"UPL\", \"WIPRO\"\n",
        "]\n",
        "\n",
        "CHELSEA01 = [\"ASLIND\", \"TAKE\", \"BANCOINDIA\",\"KESORAMIND\", \"BEL\", \"LOTUSEYE\", \"AXISILVER\",\"CRAFTSMAN\",\n",
        "             \"CUB\", \"QGOLDHALF\", \"SILVER\", \"KAPSTON\", \"SABEVENTS\", \"TDPOWERSYS\", \"BLISSGVS\", \"SANSERA\",\n",
        "             \"LUMAXIND\", \"MRPL\", \"PRECWIRE\", \"EGOLD\", \"KRISHANA\", \"NETWEB\", \"BGRENERGY\", \"HAPPYFORGE\", \"GENCON\",\n",
        "             \"CMMIPL\", \"AVANTIFEED\", \"BHARATWIRE\", \"GVT&D\", \"POWERINDIA\", \"LTF\", \"ABINFRA\", \"UNIONBANK\", \"BANKINDIA\",\n",
        "             \"CUPID\", \"SMSPHARMA\", \"UNIHEALTH\", \"VMARCIND\", \"TFCILTD\", \"DCBBANK\", \"KARURVYSYA\", \"TCIEXP\"]\n",
        "\n",
        "Bharath = [\"ACUTAAS\", \"PARKHOTELS\", \"APOLLOHOSP\", \"BAJAJ-AUTO\", \"CANROBO\",\n",
        "       \"CAMS\", \"CONTROLPR\", \"CROMPTON\", \"DABUR\", \"GRSE\",\n",
        "       \"MEDANTA\", \"HEG\", \"KOTAKBANK\", \"LT\", \"LICHSGFIN\",\n",
        "       \"REPCOHOME\", \"SAILIFE\", \"SKYGOLD\", \"SPAL\", \"SBIN\",\n",
        "       \"V2RETAIL\", \"WABAG\", \"VBL\"]\n",
        "\n",
        "COMPANY_STARTING_WITH_A_SYMBOLS = [\n",
        "    \"A2ZMES\", \"AANJANEYA\", \"AARTIDRUGS\", \"AARTIIND\", \"AARVEEDEN\", \"ABAN\",\n",
        "    \"ABB\", \"ABCIL\", \"ABGSHIP\", \"ABIRLANUVO\", \"ACC\", \"ACE\", \"ACKRUTI\", \"ADANIENT\",\n",
        "    \"ACROPETAL\", \"ADANIPOWER\", \"ADFFOODS\", \"ADHUNIK\", \"ADORWELD\", \"ADSL\",\n",
        "    \"ADVANIHOTR\", \"ADVANTA\", \"AEGISCHEM\", \"AFL\", \"AFTEK\", \"AGCNET\", \"AGRODUTCH\",\n",
        "    \"AHLEAST\", \"AHLUCONT\", \"AHLWEST\", \"AHMEDFORGE\", \"AIAENG\", \"AICHAMP\", \"AJANTPHARM\",\n",
        "    \"AJMERA\", \"AKSHOPTFBR\", \"AKZOINDIA\", \"ALBK\", \"ALCHEM\", \"ALEMBICLTD\",\n",
        "    \"ALFALAVAL\", \"ALICON\", \"ALKALI\", \"ALKYLAMINE\", \"ALLCARGO\", \"ALLSEC\",\n",
        "    \"ALMONDZ\", \"ALOKTEXT\", \"ALPHAGEO\", \"AMAR\", \"AMARAJABAT\", \"ALPSINDUS\", \"AMBIKCO\",\n",
        "    \"AMBUJACEM\", \"AMDIND\", \"AMTEKAUTO\", \"AMTEKINDIA\", \"ANANTRAJ\", \"ANDHRABANK\",\n",
        "    \"ANDHRSUGAR\", \"ANGIND\", \"ANIKINDS\", \"ANDHRACEMT\", \"ANKURDRUGS\", \"ANSALAPI\",\n",
        "    \"ANSALHSG\", \"ANTGRAPHIC\", \"APARINDS\", \"APCOTEXIND\", \"APIL\", \"APOLLOHOSP\",\n",
        "    \"APOLLOTYRE\", \"APPAPER\", \"APTECHT\", \"AQUA\", \"ARCHIDPLY\", \"ARCHIES\", \"AREVAT&D\"\n",
        "]\n",
        "\n",
        "def find_data_root(base_folder):\n",
        "    \"\"\"\n",
        "    Recursively search for Companies_list.csv to detect valid data root.\n",
        "    \"\"\"\n",
        "    for root, dirs, files in os.walk(base_folder):\n",
        "        if \"Companies_list.csv\" in files and \"HISTORICAL_DATA\" in dirs:\n",
        "            return root\n",
        "    return None\n",
        "\n",
        "def download_and_extract_google_drive_zip_1(file_id, extract_to=\"stock_data\"):\n",
        "    \"\"\"\n",
        "    Downloads and extracts Google Drive ZIP safely.\n",
        "    Automatically detects correct nested root folder.\n",
        "    \"\"\"\n",
        "    os.makedirs(extract_to, exist_ok=True)\n",
        "    existing_root = find_data_root(extract_to)\n",
        "    if existing_root is not None:\n",
        "        print(f\"Data already exists at: {existing_root}\")\n",
        "        print(\"Skipping download.\")\n",
        "        return existing_root\n",
        "    zip_path = os.path.join(extract_to, \"stock_data.zip\")\n",
        "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "    print(\"Downloading from Google Drive...\")\n",
        "    gdown.download(url, zip_path, quiet=False)\n",
        "    print(\"Extracting zip...\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "    print(\"Extraction complete.\")\n",
        "    for root, dirs, files in os.walk(extract_to): # recursively find Companies_list.csv\n",
        "        if \"Companies_list.csv\" in files:\n",
        "            print(\"Correct data root detected:\", root)\n",
        "            return root\n",
        "    raise Exception(\"Could not find Companies_list.csv in extracted contents\")\n",
        "\n",
        "def load_company_csv_strict(path: str, symbol: str) -> pd.DataFrame | None:\n",
        "    \"\"\"\n",
        "    Load single CSV only if it contains 'Date' and a close-like column.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        raw = pd.read_csv(path, low_memory=False)\n",
        "        raw.columns = [str(c).strip() for c in raw.columns]\n",
        "        # find exact date column (case-insensitive)\n",
        "        date_col = next((c for c in raw.columns if c.lower() == \"date\"), None)\n",
        "        if date_col is None:\n",
        "            # skip\n",
        "            # print(f\"Skipping {symbol}: no Date column\")\n",
        "            return None\n",
        "        raw[date_col] = pd.to_datetime(raw[date_col], errors=\"coerce\")\n",
        "        raw = raw.dropna(subset=[date_col])\n",
        "        close_candidates = [c for c in raw.columns if c.lower() in (\"adj_close\",\"adj close\",\"close\",\"close_price\",\"close price\")]\n",
        "        if not close_candidates:\n",
        "            # skip\n",
        "            # print(f\"Skipping {symbol}: no close column\")\n",
        "            return None\n",
        "        close_col = close_candidates[0]\n",
        "        df = raw[[date_col, close_col]].rename(columns={date_col: \"Date\", close_col: symbol})\n",
        "        df = df.dropna().drop_duplicates(subset=[\"Date\"]).sort_values(\"Date\").set_index(\"Date\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {symbol} from {path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def read_stock_data_from_folder(folder_path):\n",
        "    \"\"\"\n",
        "    Reads stock dataset using:\n",
        "\n",
        "    folder_path/\n",
        "        Companies_list.csv\n",
        "        HISTORICAL_DATA/*.csv\n",
        "\n",
        "    Returns optimizer-compatible dataframe:\n",
        "    date, SYMBOL1, SYMBOL2, SYMBOL3...\n",
        "    \"\"\"\n",
        "\n",
        "    companies_csv = os.path.join(folder_path, \"Companies_list.csv\")\n",
        "    hist_dir = os.path.join(folder_path, \"HISTORICAL_DATA\")\n",
        "    if not os.path.exists(companies_csv):\n",
        "        raise Exception(\"Companies_list.csv not found\")\n",
        "    if not os.path.exists(hist_dir):\n",
        "        raise Exception(\"HISTORICAL_DATA folder not found\")\n",
        "    companies_df = pd.read_csv(companies_csv)\n",
        "    companies_df.columns = [c.strip() for c in companies_df.columns]\n",
        "    symbol_col = next(\n",
        "        (c for c in companies_df.columns\n",
        "         if c.lower() in (\"symbol\", \"ticker\", \"company\", \"stock\", \"code\")),\n",
        "        companies_df.columns[0]\n",
        "    )\n",
        "    symbols = companies_df[symbol_col].astype(str).tolist()\n",
        "    files = glob.glob(os.path.join(hist_dir, \"*_data.csv\"))\n",
        "    file_map = {}\n",
        "    for f in files:\n",
        "        name = os.path.basename(f)\n",
        "        prefix = name.replace(\"_data.csv\", \"\")\n",
        "        file_map[prefix.upper()] = f\n",
        "    frames = []\n",
        "    loaded_symbols = []\n",
        "    for symbol in symbols:\n",
        "        symbol_upper = symbol.upper()\n",
        "        if symbol_upper not in file_map:\n",
        "            continue\n",
        "        df = load_company_csv_strict(file_map[symbol_upper], symbol)\n",
        "        if df is not None and not df.empty:\n",
        "            frames.append(df)\n",
        "            loaded_symbols.append(symbol)\n",
        "    if not frames:\n",
        "        raise Exception(\"No valid CSV files found after strict cleaning\")\n",
        "    panel = pd.concat(frames, axis=1, join=\"outer\")\n",
        "    panel = panel.sort_index().ffill()\n",
        "    # convert to optimizer format\n",
        "    panel.reset_index(inplace=True)\n",
        "    panel.rename(columns={\"Date\": \"date\"}, inplace=True)\n",
        "    panel[\"date\"] = panel[\"date\"].astype(str)\n",
        "    print(f\"Loaded {len(loaded_symbols)} valid symbols\")\n",
        "    return panel\n",
        "\n",
        "def download_and_extract_google_drive_zip_2(file_id, extract_to=\"bse_data\"):\n",
        "    os.makedirs(extract_to, exist_ok=True)\n",
        "    zip_path = os.path.join(extract_to, \"stock_data_24_26_25Feb26.zip\")\n",
        "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "    if not os.path.exists(zip_path):\n",
        "        print(\"Downloading ZIP from Google Drive...\")\n",
        "        gdown.download(url, zip_path, quiet=False)\n",
        "    print(\"Extracting ZIP...\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "    print(\"Extraction complete.\")\n",
        "    # Return actual CSV folder directly\n",
        "    csv_folder = os.path.join(extract_to, \"stock_data_24_26_25Feb26\")\n",
        "    return csv_folder\n",
        "\n",
        "def select_top_by_turnover(df, top_n=100):\n",
        "    avg_turnover = (\n",
        "        df.groupby(\"symbol\")[\"turnover\"]\n",
        "        .mean()\n",
        "        .sort_values(ascending=False)\n",
        "    )\n",
        "    return avg_turnover.head(top_n).index.tolist()\n",
        "\n",
        "def select_random(df, top_n=100, seed=42):\n",
        "    np.random.seed(seed)\n",
        "    symbols = df[\"symbol\"].unique()\n",
        "    return list(np.random.choice(symbols, size=min(top_n, len(symbols)), replace=False))\n",
        "\n",
        "def select_price_filter(df, min_price=50):\n",
        "    avg_price = df.groupby(\"symbol\")[\"close\"].mean()\n",
        "    return avg_price[avg_price > min_price].index.tolist()\n",
        "\n",
        "def select_turnover_and_price(df, top_n=150, min_price=50):\n",
        "    df_filtered = df[df[\"close\"] > min_price]\n",
        "    return select_top_by_turnover(df_filtered, top_n=top_n)\n",
        "\n",
        "def read_bse_bhavcopy_folder(\n",
        "    folder_path,\n",
        "    strategy=None,\n",
        "    strategy_params=None\n",
        "):\n",
        "    \"\"\"\n",
        "    strategy:\n",
        "        \"top_turnover\"\n",
        "        \"random\"\n",
        "        \"price_filter\"\n",
        "        \"turnover_price\"\n",
        "        None  â†’ no filtering (ALL stocks)\n",
        "    returns data in\n",
        "    Date firm1 firm2...\n",
        "    ...  price price...\n",
        "    \"\"\"\n",
        "    if strategy_params is None:\n",
        "        strategy_params = {}\n",
        "    print(\"Scanning CSV files...\")\n",
        "    csv_files = glob.glob(os.path.join(folder_path, \"**/*.[cC][sS][vV]\"), recursive=True)\n",
        "    if not csv_files:\n",
        "        raise Exception(\"No CSV files found.\")\n",
        "    all_data = []\n",
        "    for file in csv_files:\n",
        "        try:\n",
        "            df = pd.read_csv(file, low_memory=False)\n",
        "            required_cols = [\"TradDt\", \"TckrSymb\", \"ClsPric\", \"TtlTrfVal\"]\n",
        "            if not all(col in df.columns for col in required_cols):\n",
        "                continue\n",
        "            df = df[required_cols].copy()\n",
        "            df[\"TradDt\"] = pd.to_datetime(df[\"TradDt\"], errors=\"coerce\")\n",
        "            df[\"TtlTrfVal\"] = pd.to_numeric(df[\"TtlTrfVal\"], errors=\"coerce\")\n",
        "            df = df.dropna(subset=[\"TradDt\", \"TckrSymb\", \"ClsPric\", \"TtlTrfVal\"])\n",
        "            df.rename(columns={\n",
        "                \"TradDt\": \"date\",\n",
        "                \"TckrSymb\": \"symbol\",\n",
        "                \"ClsPric\": \"close\",\n",
        "                \"TtlTrfVal\": \"turnover\"\n",
        "            }, inplace=True)\n",
        "\n",
        "            all_data.append(df)\n",
        "        except:\n",
        "            continue\n",
        "    if not all_data:\n",
        "        raise Exception(\"No valid bhav copy data found.\")\n",
        "    combined = pd.concat(all_data, ignore_index=True)\n",
        "    # Strategy Selection\n",
        "    if strategy is None:\n",
        "      print(\"Strategy: None (returning ALL stocks)\")\n",
        "      selected_symbols = combined[\"symbol\"].unique().tolist()\n",
        "    elif strategy == \"top_turnover\":\n",
        "        selected_symbols = select_top_by_turnover(combined, **strategy_params)\n",
        "    elif strategy == \"random\":\n",
        "        selected_symbols = select_random(combined, **strategy_params)\n",
        "    elif strategy == \"price_filter\":\n",
        "        selected_symbols = select_price_filter(combined, **strategy_params)\n",
        "    elif strategy == \"turnover_price\":\n",
        "        selected_symbols = select_turnover_and_price(combined, **strategy_params)\n",
        "    elif strategy is None:\n",
        "        selected_symbols = combined[\"symbol\"].unique().tolist()\n",
        "    else:\n",
        "        raise ValueError(\"Unknown strategy\")\n",
        "    print(f\"Strategy: {strategy}\")\n",
        "    print(f\"Selected {len(selected_symbols)} stocks\")\n",
        "    combined = combined[combined[\"symbol\"].isin(selected_symbols)]\n",
        "    # Pivot\n",
        "    panel = combined.pivot_table(\n",
        "        index=\"date\",\n",
        "        columns=\"symbol\",\n",
        "        values=\"close\",\n",
        "        aggfunc=\"first\"\n",
        "    )\n",
        "    panel = panel.sort_index().ffill()\n",
        "    panel.reset_index(inplace=True)\n",
        "    panel[\"date\"] = panel[\"date\"].astype(str)\n",
        "    print(f\"Final dataset shape: {panel.shape}\")\n",
        "    return panel\n",
        "\n",
        "def filter_dataset(\n",
        "    df,\n",
        "    start_date=None,\n",
        "    end_date=None,\n",
        "    company_codes=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Filters dataset based on tunable parameters...\n",
        "\n",
        "    INPUTS:\n",
        "    df            : pandas DataFrame dataset in specified format\n",
        "    start_date    : str or None starting date to include\n",
        "    end_date      : str or None ending date to include\n",
        "    company_codes : list[str] or None list of company columns to keep\n",
        "\n",
        "    OUTPUT:\n",
        "    filtered_df   : pandas DataFrame\n",
        "\n",
        "    INPUT DATAFRAME FORMAT:\n",
        "    First column      : date (string / datetime / month)\n",
        "    Remaining columns : stock prices\n",
        "    Each row          : time snapshot\n",
        "    Each column       : stock price of that company at that time\n",
        "    example           :\n",
        "    date,    AAPL, MSFT, GOOG, AMZN\n",
        "    2020-01, 100, 200, 300, 400\n",
        "    2020-02, 105, 210, 290, 420\n",
        "    2020-03, 110, 220, 310, 430\n",
        "    \"\"\"\n",
        "\n",
        "    filtered = df.copy()\n",
        "    filtered['date'] = pd.to_datetime(filtered['date']) # Ensure date column is datetime for comparison\n",
        "    if start_date is not None: # Filter by start date\n",
        "        filtered = filtered[filtered['date'] >= pd.to_datetime(start_date)]\n",
        "    if end_date is not None: # Filter by end date\n",
        "        filtered = filtered[filtered['date'] <= pd.to_datetime(end_date)]\n",
        "    if company_codes is not None: # Filter company columns\n",
        "        filtered = filtered[['date'] + company_codes]\n",
        "    filtered = filtered.reset_index(drop=True) # Reset index\n",
        "    return filtered\n",
        "\n",
        "def compute_returns(price_df):\n",
        "    \"\"\"\n",
        "    Converts price data into return data...\n",
        "\n",
        "    INPUT:\n",
        "    price_df : pandas DataFrame\n",
        "\n",
        "    RETURN DEFINTITION:\n",
        "    r_t = (P_t - P_(t-1)) / P_(t-1)\n",
        "\n",
        "    OUTPUT:\n",
        "    returns_df : pandas DataFrame\n",
        "    \"\"\"\n",
        "    prices = price_df.copy()\n",
        "    prices.set_index('date', inplace=True)\n",
        "    # Remove columns that contain ANY NaN in the selected window\n",
        "    prices = prices.dropna(axis=1, how=\"any\")\n",
        "    returns_df = prices.pct_change().dropna()\n",
        "    return returns_df\n",
        "\n",
        "def portfolio_optimizer(returns_df, risk_free_rate=0.0, allow_short=True):\n",
        "    \"\"\"\n",
        "    Performs closed-form portfolio optimisation.\n",
        "\n",
        "    INPUT:\n",
        "    returns_df      : pandas DataFrame\n",
        "    risk_free_rate  : float\n",
        "\n",
        "    OUTPUT:\n",
        "    results         : dictionary\n",
        "                        mean return vector\n",
        "                        covariance matrix\n",
        "                        GMVP portfolio (min variance)\n",
        "                        MRR portfolio (max sharpe)\n",
        "    \"\"\"\n",
        "\n",
        "    returns = returns_df.values # Convert to numpy\n",
        "\n",
        "    # edge case: if portfolio by chance has only one stock\n",
        "    if returns.shape[1] == 1:\n",
        "      mu = returns.mean(axis=0)[0]\n",
        "      sigma = returns.std(axis=0)[0]\n",
        "      return {\n",
        "          \"mean_returns\": np.array([mu]),\n",
        "          \"std_returns\": np.array([sigma]),\n",
        "          \"covariance_matrix\": np.array([[sigma**2]]),\n",
        "          \"gmvp\": {\n",
        "              \"weights\": np.array([1.0]),\n",
        "              \"return\": mu,\n",
        "              \"risk\": sigma\n",
        "          },\n",
        "          \"mrr\": {\n",
        "              \"weights\": np.array([1.0]),\n",
        "              \"return\": mu,\n",
        "              \"risk\": sigma,\n",
        "              \"sharpe\": (mu - risk_free_rate) / sigma\n",
        "          }\n",
        "      }\n",
        "\n",
        "    mu = np.mean(returns, axis=0) # Mean returns vector\n",
        "    Sigma = np.cov(returns, rowvar=False) # Covariance matrix\n",
        "    Sigma_inv = np.linalg.inv(Sigma) # Inverse covariance\n",
        "    n = len(mu)\n",
        "    ones = np.ones(n)\n",
        "\n",
        "    # GMVP Portfolio\n",
        "    w_gmvp = Sigma_inv @ ones\n",
        "    w_gmvp = w_gmvp / (ones.T @ Sigma_inv @ ones)\n",
        "    if not allow_short: # enforce long-only constraint if short selling not allowed\n",
        "      w_gmvp = np.maximum(w_gmvp, 0)\n",
        "      w_gmvp = w_gmvp / np.sum(w_gmvp)\n",
        "    gmvp_return = w_gmvp @ mu\n",
        "    gmvp_var = w_gmvp.T @ Sigma @ w_gmvp\n",
        "    gmvp_std = np.sqrt(gmvp_var)\n",
        "\n",
        "    # MRR Portfolio\n",
        "    excess_returns = mu - risk_free_rate\n",
        "    w_tan = Sigma_inv @ excess_returns\n",
        "    w_tan = w_tan / (ones.T @ Sigma_inv @ excess_returns)\n",
        "    if not allow_short: # enforce long-only constraint if short selling not allowed\n",
        "      w_tan = np.maximum(w_tan, 0)\n",
        "      w_tan = w_tan / np.sum(w_tan)\n",
        "    tan_return = w_tan @ mu\n",
        "    tan_var = w_tan.T @ Sigma @ w_tan\n",
        "    tan_std = np.sqrt(tan_var)\n",
        "    tan_sharpe = (tan_return - risk_free_rate) / tan_std\n",
        "\n",
        "    stock_std = np.sqrt(np.diag(Sigma)) # Individual stock stats\n",
        "    results = {\n",
        "        \"mean_returns\": mu,\n",
        "        \"std_returns\": stock_std,\n",
        "        \"covariance_matrix\": Sigma,\n",
        "        \"gmvp\": {\n",
        "            \"weights\": w_gmvp,\n",
        "            \"return\": gmvp_return,\n",
        "            \"risk\": gmvp_std\n",
        "        },\n",
        "        \"mrr\": {\n",
        "            \"weights\": w_tan,\n",
        "            \"return\": tan_return,\n",
        "            \"risk\": tan_std,\n",
        "            \"sharpe\": tan_sharpe\n",
        "        }\n",
        "    }\n",
        "    return results\n",
        "\n",
        "def optimized_portfolio_printer(results):\n",
        "    print(\"\\nMean returns:\")\n",
        "    print(results[\"mean_returns\"])\n",
        "    print(\"\\nStd deviation:\")\n",
        "    print(results[\"std_returns\"])\n",
        "    print(\"\\nGMVP weights:\")\n",
        "    print(results[\"gmvp\"][\"weights\"])\n",
        "    print(\"\\nGMVP return:\", results[\"gmvp\"][\"return\"])\n",
        "    print(\"GMVP risk:\", results[\"gmvp\"][\"risk\"])\n",
        "    print(\"\\nMRR weights:\")\n",
        "    print(results[\"mrr\"][\"weights\"])\n",
        "    print(\"\\nMRR return:\", results[\"mrr\"][\"return\"])\n",
        "    print(\"MRR risk:\", results[\"mrr\"][\"risk\"])\n",
        "    print(\"MRR Sharpe:\", results[\"mrr\"][\"sharpe\"])\n",
        "\n",
        "def BRUTE_FORCE_find_best_portfolios_of_size_x(\n",
        "    filtered_df,\n",
        "    x,\n",
        "    risk_free_rate=0.0,\n",
        "    allow_short=True\n",
        "):\n",
        "    \"\"\"\n",
        "    Try all combinations of size x.\n",
        "\n",
        "    INPUT:\n",
        "    filtered_df     : pandas DataFrame\n",
        "    x               : size of portfolio\n",
        "    risk_free_rate  : float\n",
        "\n",
        "    OUTPUT:\n",
        "    best_gmvp       : Best GMVP portfolio dictionary\n",
        "    best_mrr        : Best MRR portfolio dictionary\n",
        "\n",
        "    COMPLEXITY: O(n choose x) ~\n",
        "    n: company pool size\n",
        "    x: portfolio size\n",
        "    \"\"\"\n",
        "\n",
        "    companies = list(filtered_df.columns)\n",
        "    companies.remove(\"date\")\n",
        "    total_combinations = math.comb(len(companies), x)\n",
        "    best_gmvp = None\n",
        "    best_gmvp_risk = np.inf\n",
        "    best_mrr = None\n",
        "    best_mrr_sharpe = -np.inf\n",
        "    processed = 0\n",
        "    checked = 0\n",
        "    dropped = 0\n",
        "    print(f\"\\nTesting {len(companies)} choose {x} combinations...\")\n",
        "    for combo in itertools.combinations(companies, x):\n",
        "        processed += 1\n",
        "        sub_df = filter_dataset(filtered_df, company_codes=list(combo))\n",
        "        returns = compute_returns(sub_df)\n",
        "        if returns.shape[0] < 2 or returns.shape[1] < x: # ensure enough data\n",
        "          dropped += 1\n",
        "          continue\n",
        "        Sigma = np.cov(returns.values, rowvar=False) # compute covariance matrix\n",
        "        det = np.linalg.det(Sigma) # skip singular covariance matrix\n",
        "        if abs(det) < 1e-12:\n",
        "          dropped += 1\n",
        "          continue\n",
        "        checked += 1\n",
        "        results = portfolio_optimizer(returns, risk_free_rate, allow_short) # safe to optimize\n",
        "        gmvp_risk = results[\"gmvp\"][\"risk\"]\n",
        "        mrr_sharpe = results[\"mrr\"][\"sharpe\"]\n",
        "        # Track best GMVP\n",
        "        if gmvp_risk < best_gmvp_risk:\n",
        "            best_gmvp_risk = gmvp_risk\n",
        "            best_gmvp = {\n",
        "                \"companies\": combo,\n",
        "                \"gmvp\": results[\"gmvp\"],\n",
        "                \"mrr\": results[\"mrr\"]\n",
        "            }\n",
        "\n",
        "        # Track best MRR\n",
        "        if mrr_sharpe > best_mrr_sharpe:\n",
        "            best_mrr_sharpe = mrr_sharpe\n",
        "            best_mrr = {\n",
        "                \"companies\": combo,\n",
        "                \"gmvp\": results[\"gmvp\"],\n",
        "                \"mrr\": results[\"mrr\"]\n",
        "            }\n",
        "\n",
        "        if processed % 10000 == 0:\n",
        "            print(\n",
        "                f\"Processed {processed}/{total_combinations} | \"\n",
        "                f\"Checked {checked} | Dropped {dropped} | \"\n",
        "                f\"Best GMVP risk={best_gmvp_risk:.6f}, return={best_gmvp['gmvp']['return']:.6f} | \"\n",
        "                f\"Best MRR return={best_mrr['mrr']['return']:.6f}, risk={best_mrr['mrr']['risk']:.6f}\"\n",
        "            )\n",
        "    print(\"\\n===== FINAL SUMMARY =====\")\n",
        "    print(f\"Total combinations: {total_combinations}\")\n",
        "    print(f\"Processed: {processed}\")\n",
        "    print(f\"Valid (checked): {checked}\")\n",
        "    print(f\"Dropped: {dropped}\")\n",
        "    print(f\"Drop rate: {100*dropped/processed:.2f}%\")\n",
        "    return best_gmvp, best_mrr\n",
        "\n",
        "\n",
        "def BEAM_SEARCH_find_best_portfolios_of_size_x(\n",
        "    filtered_df,\n",
        "    x,\n",
        "    risk_free_rate=0.0,\n",
        "    allow_short=True,\n",
        "    beam_width=10,\n",
        "    random_samples=5000,\n",
        "    sharpe_filter_size=30,\n",
        "    corr_threshold=0.9 # stocks with corr > 0.9 cropped off\n",
        "):\n",
        "    \"\"\"\n",
        "    Greedy Heuristic\n",
        "    Step 1: Sharpe filter: Some stocks are clearly bad: Low return, High volatility, poor sharpe: Will never appear in an optimal portfolio\n",
        "            Modern portfolio theory tells us optimal portfolios lie in span of high-Sharpe assets. Low-Sharpe assets almost never contribute\n",
        "    Step 2: Correlation pruning: if two stocks are highly correlated, they move almost identically, owning both adds little diversification.\n",
        "    Step 3: Beam search: Instead of trying all combinations, grow portfolios step-by-step. At each step, keep only the best few candidates (=beam width)\n",
        "    Step 4: Random refinement: Beam search is is greedy -> it may miss some good combinations (local oprimization) -> Explore regions beam search may miss\n",
        "            Random sampling converges to global optimum as samples increase (Monte Carlo optimization principle)\n",
        "\n",
        "    COMPLEXITY: O(knx)\n",
        "    k: beam size\n",
        "    n: company pool size\n",
        "    x: portfolio size\n",
        "    \"\"\"\n",
        "\n",
        "    companies = list(filtered_df.columns)\n",
        "    companies.remove(\"date\")\n",
        "    print(\"\\n===== STEP 1: Sharpe filtering =====\")\n",
        "    base_returns = compute_returns(filtered_df)\n",
        "    mean = base_returns.mean()\n",
        "    std = base_returns.std()\n",
        "    sharpe = (mean - risk_free_rate) / std\n",
        "    sharpe = sharpe.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "    sharpe_sorted = sharpe.sort_values(ascending=False)\n",
        "    filtered_companies = list(sharpe_sorted.head(sharpe_filter_size).index)\n",
        "    print(f\"Reduced from {len(companies)} to {len(filtered_companies)} stocks by Sharpe\")\n",
        "    print(\"\\n===== STEP 2: Correlation pruning =====\")\n",
        "    corr = base_returns[filtered_companies].corr().abs()\n",
        "    selected_uncorr = []\n",
        "    for stock in filtered_companies:\n",
        "        keep = True\n",
        "        for s in selected_uncorr:\n",
        "            if corr.loc[stock, s] > corr_threshold:\n",
        "                keep = False\n",
        "                break\n",
        "        if keep:\n",
        "            selected_uncorr.append(stock)\n",
        "    print(f\"Reduced to {len(selected_uncorr)} stocks after correlation pruning\")\n",
        "    search_space = selected_uncorr\n",
        "    total_combinations = math.comb(len(search_space), x) if len(search_space) >= x else 0\n",
        "    best_gmvp = None\n",
        "    best_gmvp_risk = np.inf\n",
        "    best_mrr = None\n",
        "    best_mrr_sharpe = -np.inf\n",
        "    processed = 0\n",
        "    checked = 0\n",
        "    dropped = 0\n",
        "    print(f\"\\nTesting heuristic search over reduced space...\")\n",
        "    print(\"\\n===== STEP 3: Beam search =====\")\n",
        "    beam = [([], None)]\n",
        "    for depth in range(x):\n",
        "        candidates = []\n",
        "        for combo, _ in beam:\n",
        "            for stock in search_space:\n",
        "                if stock in combo:\n",
        "                    continue\n",
        "                new_combo = combo + [stock]\n",
        "                sub_df = filter_dataset(filtered_df, company_codes=new_combo)\n",
        "                returns = compute_returns(sub_df)\n",
        "                if returns.shape[1] < len(new_combo):\n",
        "                    dropped += 1\n",
        "                    continue\n",
        "                Sigma = np.cov(returns.values, rowvar=False)\n",
        "                if np.ndim(Sigma) < 2:\n",
        "                    results = portfolio_optimizer(\n",
        "                        returns,\n",
        "                        risk_free_rate,\n",
        "                        allow_short\n",
        "                    )\n",
        "                else:\n",
        "                    if np.linalg.cond(Sigma) > 1e12:\n",
        "                        dropped += 1\n",
        "                        continue\n",
        "                    results = portfolio_optimizer(\n",
        "                        returns,\n",
        "                        risk_free_rate,\n",
        "                        allow_short\n",
        "                    )\n",
        "                sharpe_val = results[\"mrr\"][\"sharpe\"]\n",
        "                candidates.append((new_combo, sharpe_val, results))\n",
        "                processed += 1\n",
        "                checked += 1\n",
        "                gmvp_risk = results[\"gmvp\"][\"risk\"]\n",
        "                mrr_sharpe = results[\"mrr\"][\"sharpe\"]\n",
        "                # Track best GMVP\n",
        "                if gmvp_risk < best_gmvp_risk:\n",
        "                    best_gmvp_risk = gmvp_risk\n",
        "                    best_gmvp = {\n",
        "                        \"companies\": tuple(new_combo),\n",
        "                        \"gmvp\": results[\"gmvp\"],\n",
        "                        \"mrr\": results[\"mrr\"]\n",
        "                    }\n",
        "                # Track best MRR\n",
        "                if mrr_sharpe > best_mrr_sharpe:\n",
        "                    best_mrr_sharpe = mrr_sharpe\n",
        "                    best_mrr = {\n",
        "                        \"companies\": tuple(new_combo),\n",
        "                        \"gmvp\": results[\"gmvp\"],\n",
        "                        \"mrr\": results[\"mrr\"]\n",
        "                    }\n",
        "        candidates.sort(key=lambda x: x[1], reverse=True)\n",
        "        beam = [(c[0], c[2]) for c in candidates[:beam_width]]\n",
        "        print(\n",
        "            f\"Depth {depth+1}/{x} | \"\n",
        "            f\"Processed {processed} | Checked {checked} | Dropped {dropped} | \"\n",
        "            f\"Best GMVP risk={best_gmvp_risk:.6f}, return={best_gmvp['gmvp']['return']:.6f} | \"\n",
        "            f\"Best MRR return={best_mrr['mrr']['return']:.6f}, risk={best_mrr['mrr']['risk']:.6f}\"\n",
        "        )\n",
        "    print(\"\\n===== STEP 4: Random refinement =====\")\n",
        "    for i in range(random_samples):\n",
        "        combo = tuple(np.random.choice(search_space, x, replace=True))\n",
        "        sub_df = filter_dataset(filtered_df, company_codes=list(combo))\n",
        "        returns = compute_returns(sub_df)\n",
        "        if returns.shape[1] < x:\n",
        "            dropped += 1\n",
        "            continue\n",
        "        Sigma = np.cov(returns.values, rowvar=False)\n",
        "        if np.ndim(Sigma) < 2:\n",
        "            results = portfolio_optimizer(\n",
        "                returns,\n",
        "                risk_free_rate,\n",
        "                allow_short\n",
        "            )\n",
        "        else:\n",
        "            if np.linalg.cond(Sigma) > 1e12:\n",
        "                dropped += 1\n",
        "                continue\n",
        "            results = portfolio_optimizer(\n",
        "                returns,\n",
        "                risk_free_rate,\n",
        "                allow_short\n",
        "            )\n",
        "        processed += 1\n",
        "        checked += 1\n",
        "        gmvp_risk = results[\"gmvp\"][\"risk\"]\n",
        "        mrr_sharpe = results[\"mrr\"][\"sharpe\"]\n",
        "\n",
        "        if gmvp_risk < best_gmvp_risk:\n",
        "            best_gmvp_risk = gmvp_risk\n",
        "            best_gmvp = {\n",
        "                \"companies\": combo,\n",
        "                \"gmvp\": results[\"gmvp\"],\n",
        "                \"mrr\": results[\"mrr\"]\n",
        "            }\n",
        "\n",
        "        if mrr_sharpe > best_mrr_sharpe:\n",
        "            best_mrr_sharpe = mrr_sharpe\n",
        "            best_mrr = {\n",
        "                \"companies\": combo,\n",
        "                \"gmvp\": results[\"gmvp\"],\n",
        "                \"mrr\": results[\"mrr\"]\n",
        "            }\n",
        "\n",
        "        if i % 1000 == 0 and i > 0:\n",
        "            print(\n",
        "                f\"Random {i}/{random_samples} | \"\n",
        "                f\"Processed {processed} | Checked {checked} | Dropped {dropped} | \"\n",
        "                f\"Best GMVP risk={best_gmvp_risk:.6f}, return={best_gmvp['gmvp']['return']:.6f} | \"\n",
        "                f\"Best MRR return={best_mrr['mrr']['return']:.6f}, risk={best_mrr['mrr']['risk']:.6f}\"\n",
        "            )\n",
        "    print(\"\\n===== FINAL SUMMARY =====\")\n",
        "    print(f\"Total combinations (original space): {total_combinations}\")\n",
        "    print(f\"Processed: {processed}\")\n",
        "    print(f\"Valid (checked): {checked}\")\n",
        "    print(f\"Dropped: {dropped}\")\n",
        "    if processed > 0:\n",
        "        print(f\"Drop rate: {100*dropped/processed:.2f}%\")\n",
        "    else:\n",
        "        print(\"Drop rate: 0%\")\n",
        "    return best_gmvp, best_mrr\n",
        "\n",
        "\n",
        "TRADING_DAYS = 252\n",
        "RISK_FREE_RATE = (1 + 0.0667)**(1/TRADING_DAYS) - 1\n",
        "def print_portfolio(title, portfolio):\n",
        "    if portfolio is None:\n",
        "        print(f\"\\n{title}: None\")\n",
        "        return\n",
        "    companies = portfolio[\"companies\"]\n",
        "    gmvp = portfolio[\"gmvp\"]\n",
        "    mrr = portfolio[\"mrr\"]\n",
        "    gmvp_return_daily = gmvp[\"return\"]\n",
        "    gmvp_risk_daily = gmvp[\"risk\"]\n",
        "    gmvp_return_annual = gmvp_return_daily * TRADING_DAYS\n",
        "    gmvp_risk_annual = gmvp_risk_daily * math.sqrt(TRADING_DAYS)\n",
        "    mrr_return_daily = mrr[\"return\"]\n",
        "    mrr_risk_daily = mrr[\"risk\"]\n",
        "    mrr_return_annual = mrr_return_daily * TRADING_DAYS\n",
        "    mrr_risk_annual = mrr_risk_daily * math.sqrt(TRADING_DAYS)\n",
        "    sharpe_daily = mrr[\"sharpe\"]\n",
        "    sharpe_annual = sharpe_daily * math.sqrt(TRADING_DAYS)\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"{title}\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nCompanies:\")\n",
        "    for c in companies:\n",
        "        print(f\"  {c}\")\n",
        "    print(\"\\nGMVP Portfolio Weights:\")\n",
        "    print(\"-\"*40)\n",
        "    for c, w in zip(companies, gmvp[\"weights\"]):\n",
        "        print(f\"{c:15s} : {w*100:8.3f} %\")\n",
        "    print(\"\\nGMVP Performance:\")\n",
        "    print(f\"  Daily Return  : {gmvp_return_daily*100:8.4f} %\")\n",
        "    print(f\"  Daily Risk    : {gmvp_risk_daily*100:8.4f} %\")\n",
        "    print(f\"  Annual Return : {gmvp_return_annual*100:8.2f} %\")\n",
        "    print(f\"  Annual Risk   : {gmvp_risk_annual*100:8.2f} %\")\n",
        "    print(\"\\nMRR Portfolio (Max Sharpe) Weights:\")\n",
        "    print(\"-\"*40)\n",
        "    for c, w in zip(companies, mrr[\"weights\"]):\n",
        "        print(f\"{c:15s} : {w*100:8.3f} %\")\n",
        "    print(\"\\nMRR Performance:\")\n",
        "    print(f\"  Daily Return  : {mrr_return_daily*100:8.4f} %\")\n",
        "    print(f\"  Daily Risk    : {mrr_risk_daily*100:8.4f} %\")\n",
        "    print(f\"  Annual Return : {mrr_return_annual*100:8.2f} %\")\n",
        "    print(f\"  Annual Risk   : {mrr_risk_annual*100:8.2f} %\")\n",
        "    print(f\"\\nSharpe Ratio:\")\n",
        "    print(f\"  Daily Sharpe  : {sharpe_daily:8.4f}\")\n",
        "    print(f\"  Annual Sharpe : {sharpe_annual:8.4f}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "def symbol_exists_checker(available, symbols):\n",
        "    symbols_available = []\n",
        "    symbols_missing = []\n",
        "    for s in symbols:\n",
        "        if s in available:\n",
        "            symbols_available.append(s)\n",
        "        else:\n",
        "            symbols_missing.append(s)\n",
        "    print(\"Available:\", len(symbols_available))\n",
        "    print(\"Missing:\", len(symbols_missing))\n",
        "    print(\"\\nMissing symbols:\")\n",
        "    print(symbols_missing)\n",
        "    return symbols_available\n",
        "\n",
        "def export_both_portfolios_to_excel(\n",
        "    full_price_df,\n",
        "    best_gmvp,\n",
        "    best_mrr,\n",
        "    file_name=\"optimized_portfolios.xlsx\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Exports:\n",
        "    - Price table (date + portfolio stocks)\n",
        "    - Portfolio weights\n",
        "    - Performance metrics\n",
        "    Into same Excel sheet (results appended below price table)\n",
        "    \"\"\"\n",
        "    with pd.ExcelWriter(file_name, engine=\"xlsxwriter\") as writer:\n",
        "        # ================= GMVP =================\n",
        "        if best_gmvp is not None:\n",
        "            companies = list(best_gmvp[\"companies\"])\n",
        "            gmvp = best_gmvp[\"gmvp\"]\n",
        "            mrr = best_gmvp[\"mrr\"]\n",
        "            gmvp_df = full_price_df[[\"date\"] + companies].copy()\n",
        "            gmvp_df[\"date\"] = pd.to_datetime(gmvp_df[\"date\"])\n",
        "            gmvp_df = gmvp_df.sort_values(\"date\")\n",
        "            sheet_name = \"GMVP\"\n",
        "            gmvp_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "            worksheet = writer.sheets[sheet_name]\n",
        "            start_row = len(gmvp_df) + 3\n",
        "            # Write weights\n",
        "            worksheet.write(start_row, 0, \"GMVP Weights\")\n",
        "            for i, (c, w) in enumerate(zip(companies, gmvp[\"weights\"])):\n",
        "                worksheet.write(start_row + i + 1, 0, c)\n",
        "                worksheet.write(start_row + i + 1, 1, float(w))\n",
        "            # Performance metrics\n",
        "            gmvp_return_daily = gmvp[\"return\"]\n",
        "            gmvp_risk_daily = gmvp[\"risk\"]\n",
        "            gmvp_return_annual = gmvp_return_daily * TRADING_DAYS\n",
        "            gmvp_risk_annual = gmvp_risk_daily * np.sqrt(TRADING_DAYS)\n",
        "            metrics_row = start_row + len(companies) + 3\n",
        "            worksheet.write(metrics_row, 0, \"Performance Metrics\")\n",
        "            worksheet.write(metrics_row + 1, 0, \"Daily Return\")\n",
        "            worksheet.write(metrics_row + 1, 1, float(gmvp_return_daily))\n",
        "            worksheet.write(metrics_row + 2, 0, \"Daily Risk\")\n",
        "            worksheet.write(metrics_row + 2, 1, float(gmvp_risk_daily))\n",
        "            worksheet.write(metrics_row + 3, 0, \"Annual Return\")\n",
        "            worksheet.write(metrics_row + 3, 1, float(gmvp_return_annual))\n",
        "            worksheet.write(metrics_row + 4, 0, \"Annual Risk\")\n",
        "            worksheet.write(metrics_row + 4, 1, float(gmvp_risk_annual))\n",
        "        # ================= MRR =================\n",
        "        if best_mrr is not None:\n",
        "            companies = list(best_mrr[\"companies\"])\n",
        "            gmvp = best_mrr[\"gmvp\"]\n",
        "            mrr = best_mrr[\"mrr\"]\n",
        "            mrr_df = full_price_df[[\"date\"] + companies].copy()\n",
        "            mrr_df[\"date\"] = pd.to_datetime(mrr_df[\"date\"])\n",
        "            mrr_df = mrr_df.sort_values(\"date\")\n",
        "            sheet_name = \"MRR\"\n",
        "            mrr_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "            worksheet = writer.sheets[sheet_name]\n",
        "            start_row = len(mrr_df) + 3\n",
        "            # Write weights\n",
        "            worksheet.write(start_row, 0, \"MRR Weights\")\n",
        "            for i, (c, w) in enumerate(zip(companies, mrr[\"weights\"])):\n",
        "                worksheet.write(start_row + i + 1, 0, c)\n",
        "                worksheet.write(start_row + i + 1, 1, float(w))\n",
        "            # Performance metrics\n",
        "            mrr_return_daily = mrr[\"return\"]\n",
        "            mrr_risk_daily = mrr[\"risk\"]\n",
        "            mrr_return_annual = mrr_return_daily * TRADING_DAYS\n",
        "            mrr_risk_annual = mrr_risk_daily * np.sqrt(TRADING_DAYS)\n",
        "            sharpe_daily = mrr[\"sharpe\"]\n",
        "            sharpe_annual = sharpe_daily * np.sqrt(TRADING_DAYS)\n",
        "            metrics_row = start_row + len(companies) + 3\n",
        "            worksheet.write(metrics_row, 0, \"Performance Metrics\")\n",
        "            worksheet.write(metrics_row + 1, 0, \"Daily Return\")\n",
        "            worksheet.write(metrics_row + 1, 1, float(mrr_return_daily))\n",
        "            worksheet.write(metrics_row + 2, 0, \"Daily Risk\")\n",
        "            worksheet.write(metrics_row + 2, 1, float(mrr_risk_daily))\n",
        "            worksheet.write(metrics_row + 3, 0, \"Annual Return\")\n",
        "            worksheet.write(metrics_row + 3, 1, float(mrr_return_annual))\n",
        "            worksheet.write(metrics_row + 4, 0, \"Annual Risk\")\n",
        "            worksheet.write(metrics_row + 4, 1, float(mrr_risk_annual))\n",
        "            worksheet.write(metrics_row + 5, 0, \"Daily Sharpe\")\n",
        "            worksheet.write(metrics_row + 5, 1, float(sharpe_daily))\n",
        "            worksheet.write(metrics_row + 6, 0, \"Annual Sharpe\")\n",
        "            worksheet.write(metrics_row + 6, 1, float(sharpe_annual))\n",
        "    print(f\"\\nBoth portfolios with full results exported to: {file_name}\")\n",
        "\n",
        "def export_selected_companies_to_excel(\n",
        "    full_price_df,\n",
        "    company_keys,\n",
        "    file_name=\"selected_companies.xlsx\",\n",
        "    start_date=None,\n",
        "    end_date=None,\n",
        "    dropna=True\n",
        "):\n",
        "    \"\"\"\n",
        "    Exports selected company stock prices to Excel in format:\n",
        "\n",
        "    date | Company1 | Company2 | ...\n",
        "\n",
        "    PARAMETERS:\n",
        "    full_price_df : loaded dataset\n",
        "    company_keys  : list of company symbols\n",
        "    file_name     : output Excel file name\n",
        "    start_date    : optional filter\n",
        "    end_date      : optional filter\n",
        "    dropna        : remove columns with NaNs\n",
        "    \"\"\"\n",
        "    if \"date\" not in full_price_df.columns:\n",
        "        raise ValueError(\"DataFrame must contain 'date' column\")\n",
        "    df = full_price_df.copy()\n",
        "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
        "    # Check which symbols exist\n",
        "    available = set(df.columns)\n",
        "    valid_companies = [c for c in company_keys if c in available]\n",
        "    missing = [c for c in company_keys if c not in available]\n",
        "    if missing:\n",
        "        print(\"Warning: These companies were not found:\")\n",
        "        print(missing)\n",
        "    if not valid_companies:\n",
        "        raise ValueError(\"None of the requested companies exist in dataset\")\n",
        "    # Select columns\n",
        "    df = df[[\"date\"] + valid_companies]\n",
        "    # Date filtering\n",
        "    if start_date:\n",
        "        df = df[df[\"date\"] >= pd.to_datetime(start_date)]\n",
        "    if end_date:\n",
        "        df = df[df[\"date\"] <= pd.to_datetime(end_date)]\n",
        "    df = df.sort_values(\"date\").reset_index(drop=True)\n",
        "    if dropna:\n",
        "        df = df.dropna(axis=1, how=\"any\")\n",
        "    # Export to Excel\n",
        "    df.to_excel(file_name, index=False)\n",
        "    print(f\"\\nExcel file created: {file_name}\")\n",
        "    print(f\"Columns exported: {['date'] + valid_companies}\")\n",
        "    print(f\"Total rows: {len(df)}\")\n",
        "\n",
        "def data_loading_pipeline_1():\n",
        "    file_id = \"1yJuY2SF3sCllibGXeyoNNzS6v2j7g08s\"\n",
        "    root = download_and_extract_google_drive_zip_1(file_id)\n",
        "    df = read_stock_data_from_folder(root)\n",
        "    print(df.head())\n",
        "\n",
        "    available = set(df.columns)\n",
        "    existing_codes = symbol_exists_checker(available, CHELSEA01); # NIFTY50_SYMBOLS\n",
        "    print(existing_codes)\n",
        "    filtered = filter_dataset(df, start_date=\"2018-01-01\") #company_codes=existing_codes)\n",
        "    print(filtered.head())\n",
        "    print(filtered[\"date\"].min())\n",
        "    print(filtered[\"date\"].max())\n",
        "    return filtered\n",
        "\n",
        "def data_loading_pipeline_2():\n",
        "    file_id = \"1edQni7obD5aQqfgqh_-bgz0NOOj6tXG7\"\n",
        "    root = download_and_extract_google_drive_zip_2(file_id)\n",
        "    df = read_bse_bhavcopy_folder(root)\n",
        "    #df = read_bse_bhavcopy_folder(root, strategy=\"top_turnover\", strategy_params={\"top_n\": 1000}) # Top n by turnover # CONFIGURE HERE\n",
        "    #df = read_bse_bhavcopy_folder(root, strategy=\"top_turnover\", strategy_params={\"top_n\": 120}) # Random n\n",
        "    #df = read_bse_bhavcopy_folder(root, strategy=\"price_filter\", strategy_params={\"min_price\": 100}) # Price filter to remove penny stocks\n",
        "    #df = read_bse_bhavcopy_folder(root, strategy=\"turnover_price\", strategy_params={\"top_n\": 150, \"min_price\": 75})\n",
        "\n",
        "    available = set(df.columns)\n",
        "    existing_codes = symbol_exists_checker(available, CHELSEA01)  # CONFIGURE HERE\n",
        "\n",
        "    filtered = filter_dataset(\n",
        "      df,\n",
        "      start_date=\"2024-08-01\",\n",
        "      company_codes=existing_codes # CONFIGURE HERE\n",
        "    )\n",
        "\n",
        "    print(filtered.head())\n",
        "    print(filtered[\"date\"].min())\n",
        "    print(filtered[\"date\"].max())\n",
        "    return filtered\n",
        "\n",
        "def main():\n",
        "\n",
        "    # data = data_loading_pipeline_1() # for older dataset\n",
        "    data = data_loading_pipeline_2() # for newer dataset\n",
        "\n",
        "    #best_gmvp, best_mrr = BRUTE_FORCE_find_best_portfolios_of_size_x(data, x=3, risk_free_rate=RISK_FREE_RATE, allow_short=False)\n",
        "    best_gmvp, best_mrr = BEAM_SEARCH_find_best_portfolios_of_size_x(data, x=42, risk_free_rate=RISK_FREE_RATE, allow_short=False) # CONFIGURE HERE\n",
        "\n",
        "    print_portfolio(\"BEST GMVP PORTFOLIO\", best_gmvp)\n",
        "    print_portfolio(\"BEST MRR PORTFOLIO\", best_mrr)\n",
        "    # export_both_portfolios_to_excel(data, best_gmvp, best_mrr)\n",
        "\n",
        "    export_selected_companies_to_excel(\n",
        "      data,\n",
        "      #[\"VAGHANI\", \"RRP\", \"EUROASIA\", \"MIDWEST\", \"GLITTEKG\", \"IMEC\"],\n",
        "      [\"TCIEXP\",\"ASLIND\", \"TAKE\", \"BANCOINDIA\",\"KESORAMIND\", \"BEL\", \"LOTUSEYE\", \"AXISILVER\",\"CRAFTSMAN\",\"CUB\", \"QGOLDHALF\", \"SILVER\", \"KAPSTON\", \"SABEVENTS\", \"TDPOWERSYS\", \"BLISSGVS\", \"SANSERA\", \"LUMAXIND\", \"MRPL\", \"PRECWIRE\", \"EGOLD\", \"KRISHANA\", \"NETWEB\", \"BGRENERGY\", \"HAPPYFORGE\", \"GENCON\", \"CMMIPL\", \"AVANTIFEED\", \"BHARATWIRE\", \"GVT&D\", \"POWERINDIA\", \"LTF\", \"ABINFRA\", \"UNIONBANK\", \"BANKINDIA\", \"CUPID\", \"SMSPHARMA\", \"UNIHEALTH\", \"VMARCIND\", \"TFCILTD\", \"DCBBANK\", \"KARURVYSYA\"],\n",
        "      file_name=\"best_mrr3.xlsx\",\n",
        "      start_date=\"2024-08-01\"\n",
        "    )\n",
        "\n",
        "    # data = {\n",
        "    #     \"date\": [\n",
        "    #         \"2020-01\",\n",
        "    #         \"2020-02\",\n",
        "    #         \"2020-03\",\n",
        "    #         \"2020-04\",\n",
        "    #         \"2020-05\",\n",
        "    #         \"2020-06\"\n",
        "    #     ],\n",
        "    #     \"AAPL\": [100, 105, 110, 108, 115, 120],\n",
        "    #     \"MSFT\": [200, 210, 220, 215, 225, 230],\n",
        "    #     \"GOOG\": [300, 295, 310, 320, 330, 340],\n",
        "    #     \"AMZN\": [400, 420, 430, 440, 450, 460]\n",
        "    # }\n",
        "\n",
        "    # df = pd.DataFrame(data)\n",
        "    # print(\"\\nOriginal dataset:\")\n",
        "    # print(df)\n",
        "\n",
        "    # filtered = filter_dataset(df, start_date=\"2020-02\", end_date=\"2020-06\", company_codes=[\"AAPL\", \"MSFT\", \"GOOG\"])\n",
        "    # print(\"\\nFiltered dataset:\\n\", filtered)\n",
        "\n",
        "    # returns = compute_returns(filtered)\n",
        "    # print(\"\\nReturns:\\n\", returns)\n",
        "\n",
        "    # results = portfolio_optimizer(returns, risk_free_rate=0.01)\n",
        "    # optimized_portfolio_printer(results)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGgt5ASxpnML",
        "outputId": "db38dffe-1c5b-4069-d4e4-176ebdd33c30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ZIP...\n",
            "Extraction complete.\n",
            "Scanning CSV files...\n",
            "Strategy: None (returning ALL stocks)\n",
            "Strategy: None\n",
            "Selected 9163 stocks\n",
            "Final dataset shape: (363, 9164)\n",
            "Available: 33\n",
            "Missing: 9\n",
            "\n",
            "Missing symbols:\n",
            "['ASLIND', 'AXISILVER', 'KAPSTON', 'EGOLD', 'KRISHANA', 'CMMIPL', 'GVT&D', 'UNIHEALTH', 'VMARCIND']\n",
            "symbol       date   TAKE  BANCOINDIA  KESORAMIND     BEL  LOTUSEYE  CRAFTSMAN  \\\n",
            "0      2024-08-01  19.81      744.00      218.60  311.15     67.03    5542.25   \n",
            "1      2024-08-02  19.68      728.90      213.95  302.95     66.02    5354.00   \n",
            "2      2024-08-05  18.99      680.65      209.95  290.10     64.06    5184.25   \n",
            "3      2024-08-06  18.46      669.50      210.00  287.30     63.11    5176.75   \n",
            "4      2024-08-07  19.73      683.80      212.85  300.25     67.88    5196.65   \n",
            "\n",
            "symbol     CUB  QGOLDHALF  SILVER  ...     LTF  ABINFRA  UNIONBANK  BANKINDIA  \\\n",
            "0       171.95      58.77   85.33  ...  176.55      NaN     135.20     126.05   \n",
            "1       166.85      59.35   85.29  ...  177.05      NaN     133.30     126.15   \n",
            "2       162.40      58.47   82.28  ...  168.50      NaN     125.65     122.25   \n",
            "3       162.35      58.42   80.77  ...  167.15      NaN     122.55     118.95   \n",
            "4       163.70      58.00   81.04  ...  169.50      NaN     122.25     118.90   \n",
            "\n",
            "symbol  CUPID  SMSPHARMA  TFCILTD  DCBBANK  KARURVYSYA   TCIEXP  \n",
            "0       92.04     303.35   185.65   124.85      225.95  1212.30  \n",
            "1       90.60     312.55   179.90   124.55      219.00  1186.25  \n",
            "2       87.07     309.20   170.95   119.05      210.10  1135.40  \n",
            "3       91.42     276.30   170.00   119.30      206.95  1137.90  \n",
            "4       95.99     295.80   173.50   119.00      215.10  1159.00  \n",
            "\n",
            "[5 rows x 34 columns]\n",
            "2024-08-01 00:00:00\n",
            "2026-02-25 00:00:00\n",
            "\n",
            "===== STEP 1: Sharpe filtering =====\n",
            "Reduced from 33 to 30 stocks by Sharpe\n",
            "\n",
            "===== STEP 2: Correlation pruning =====\n",
            "Reduced to 30 stocks after correlation pruning\n",
            "\n",
            "Testing heuristic search over reduced space...\n",
            "\n",
            "===== STEP 3: Beam search =====\n",
            "Depth 1/42 | Processed 30 | Checked 30 | Dropped 0 | Best GMVP risk=0.015022, return=0.002461 | Best MRR return=0.006428, risk=0.039133\n",
            "Depth 2/42 | Processed 320 | Checked 320 | Dropped 0 | Best GMVP risk=0.011612, return=0.001630 | Best MRR return=0.003218, risk=0.013680\n",
            "Depth 3/42 | Processed 600 | Checked 600 | Dropped 0 | Best GMVP risk=0.010969, return=0.002058 | Best MRR return=0.003850, risk=0.014148\n",
            "Depth 4/42 | Processed 870 | Checked 870 | Dropped 0 | Best GMVP risk=0.010897, return=0.002204 | Best MRR return=0.003739, risk=0.013339\n",
            "Depth 5/42 | Processed 1130 | Checked 1130 | Dropped 0 | Best GMVP risk=0.010567, return=0.002250 | Best MRR return=0.003652, risk=0.012758\n",
            "Depth 6/42 | Processed 1380 | Checked 1380 | Dropped 0 | Best GMVP risk=0.010403, return=0.002298 | Best MRR return=0.003620, risk=0.012553\n",
            "Depth 7/42 | Processed 1620 | Checked 1620 | Dropped 0 | Best GMVP risk=0.010349, return=0.002316 | Best MRR return=0.003588, risk=0.012400\n",
            "Depth 8/42 | Processed 1850 | Checked 1850 | Dropped 0 | Best GMVP risk=0.010243, return=0.002308 | Best MRR return=0.003548, risk=0.012242\n",
            "Depth 9/42 | Processed 2070 | Checked 2070 | Dropped 0 | Best GMVP risk=0.009987, return=0.002245 | Best MRR return=0.003542, risk=0.012217\n",
            "Depth 10/42 | Processed 2280 | Checked 2280 | Dropped 0 | Best GMVP risk=0.009984, return=0.002249 | Best MRR return=0.003542, risk=0.012217\n",
            "Depth 11/42 | Processed 2480 | Checked 2480 | Dropped 0 | Best GMVP risk=0.009935, return=0.002204 | Best MRR return=0.003542, risk=0.012217\n",
            "Depth 12/42 | Processed 2670 | Checked 2670 | Dropped 0 | Best GMVP risk=0.009935, return=0.002204 | Best MRR return=0.003542, risk=0.012217\n",
            "Depth 13/42 | Processed 2850 | Checked 2850 | Dropped 0 | Best GMVP risk=0.009935, return=0.002204 | Best MRR return=0.003542, risk=0.012217\n",
            "Depth 14/42 | Processed 3020 | Checked 3020 | Dropped 0 | Best GMVP risk=0.009935, return=0.002204 | Best MRR return=0.003542, risk=0.012217\n",
            "Depth 15/42 | Processed 3180 | Checked 3180 | Dropped 0 | Best GMVP risk=0.009935, return=0.002204 | Best MRR return=0.003542, risk=0.012217\n",
            "Depth 16/42 | Processed 3330 | Checked 3330 | Dropped 0 | Best GMVP risk=0.009935, return=0.002204 | Best MRR return=0.003542, risk=0.012217\n",
            "Depth 17/42 | Processed 3470 | Checked 3470 | Dropped 0 | Best GMVP risk=0.009935, return=0.002204 | Best MRR return=0.003542, risk=0.012217\n",
            "Depth 18/42 | Processed 3600 | Checked 3600 | Dropped 0 | Best GMVP risk=0.009889, return=0.002180 | Best MRR return=0.003542, risk=0.012217\n",
            "Depth 19/42 | Processed 3720 | Checked 3720 | Dropped 0 | Best GMVP risk=0.009889, return=0.002180 | Best MRR return=0.003542, risk=0.012217\n",
            "Depth 20/42 | Processed 3830 | Checked 3830 | Dropped 0 | Best GMVP risk=0.009863, return=0.002173 | Best MRR return=0.003542, risk=0.012217\n",
            "Depth 21/42 | Processed 3930 | Checked 3930 | Dropped 0 | Best GMVP risk=0.009857, return=0.002168 | Best MRR return=0.003542, risk=0.012217\n",
            "Depth 22/42 | Processed 4020 | Checked 4020 | Dropped 0 | Best GMVP risk=0.009857, return=0.002168 | Best MRR return=0.003542, risk=0.012217\n",
            "Depth 23/42 | Processed 4100 | Checked 4100 | Dropped 0 | Best GMVP risk=0.009857, return=0.002168 | Best MRR return=0.003542, risk=0.012217\n",
            "Depth 24/42 | Processed 4170 | Checked 4170 | Dropped 0 | Best GMVP risk=0.009857, return=0.002168 | Best MRR return=0.003542, risk=0.012217\n",
            "Depth 25/42 | Processed 4230 | Checked 4230 | Dropped 0 | Best GMVP risk=0.009857, return=0.002168 | Best MRR return=0.003542, risk=0.012217\n",
            "Depth 26/42 | Processed 4280 | Checked 4280 | Dropped 0 | Best GMVP risk=0.009847, return=0.002154 | Best MRR return=0.003542, risk=0.012217\n",
            "Depth 27/42 | Processed 4320 | Checked 4320 | Dropped 0 | Best GMVP risk=0.009837, return=0.002152 | Best MRR return=0.003542, risk=0.012217\n",
            "Depth 28/42 | Processed 4350 | Checked 4350 | Dropped 0 | Best GMVP risk=0.009837, return=0.002151 | Best MRR return=0.003542, risk=0.012217\n",
            "Depth 29/42 | Processed 4370 | Checked 4370 | Dropped 0 | Best GMVP risk=0.009831, return=0.002145 | Best MRR return=0.003542, risk=0.012217\n",
            "Depth 30/42 | Processed 4380 | Checked 4380 | Dropped 0 | Best GMVP risk=0.009831, return=0.002145 | Best MRR return=0.003542, risk=0.012217\n",
            "Depth 31/42 | Processed 4380 | Checked 4380 | Dropped 0 | Best GMVP risk=0.009831, return=0.002145 | Best MRR return=0.003542, risk=0.012217\n",
            "Depth 32/42 | Processed 4380 | Checked 4380 | Dropped 0 | Best GMVP risk=0.009831, return=0.002145 | Best MRR return=0.003542, risk=0.012217\n",
            "Depth 33/42 | Processed 4380 | Checked 4380 | Dropped 0 | Best GMVP risk=0.009831, return=0.002145 | Best MRR return=0.003542, risk=0.012217\n",
            "Depth 34/42 | Processed 4380 | Checked 4380 | Dropped 0 | Best GMVP risk=0.009831, return=0.002145 | Best MRR return=0.003542, risk=0.012217\n",
            "Depth 35/42 | Processed 4380 | Checked 4380 | Dropped 0 | Best GMVP risk=0.009831, return=0.002145 | Best MRR return=0.003542, risk=0.012217\n",
            "Depth 36/42 | Processed 4380 | Checked 4380 | Dropped 0 | Best GMVP risk=0.009831, return=0.002145 | Best MRR return=0.003542, risk=0.012217\n",
            "Depth 37/42 | Processed 4380 | Checked 4380 | Dropped 0 | Best GMVP risk=0.009831, return=0.002145 | Best MRR return=0.003542, risk=0.012217\n",
            "Depth 38/42 | Processed 4380 | Checked 4380 | Dropped 0 | Best GMVP risk=0.009831, return=0.002145 | Best MRR return=0.003542, risk=0.012217\n",
            "Depth 39/42 | Processed 4380 | Checked 4380 | Dropped 0 | Best GMVP risk=0.009831, return=0.002145 | Best MRR return=0.003542, risk=0.012217\n",
            "Depth 40/42 | Processed 4380 | Checked 4380 | Dropped 0 | Best GMVP risk=0.009831, return=0.002145 | Best MRR return=0.003542, risk=0.012217\n",
            "Depth 41/42 | Processed 4380 | Checked 4380 | Dropped 0 | Best GMVP risk=0.009831, return=0.002145 | Best MRR return=0.003542, risk=0.012217\n",
            "Depth 42/42 | Processed 4380 | Checked 4380 | Dropped 0 | Best GMVP risk=0.009831, return=0.002145 | Best MRR return=0.003542, risk=0.012217\n",
            "\n",
            "===== STEP 4: Random refinement =====\n",
            "\n",
            "===== FINAL SUMMARY =====\n",
            "Total combinations (original space): 0\n",
            "Processed: 4380\n",
            "Valid (checked): 4380\n",
            "Dropped: 5000\n",
            "Drop rate: 114.16%\n",
            "\n",
            "======================================================================\n",
            "BEST GMVP PORTFOLIO\n",
            "======================================================================\n",
            "\n",
            "Companies:\n",
            "  QGOLDHALF\n",
            "  CUPID\n",
            "  BGRENERGY\n",
            "  LUMAXIND\n",
            "  SABEVENTS\n",
            "  POWERINDIA\n",
            "  TAKE\n",
            "  CUB\n",
            "  AVANTIFEED\n",
            "  LOTUSEYE\n",
            "  TDPOWERSYS\n",
            "  NETWEB\n",
            "  SILVER\n",
            "  CRAFTSMAN\n",
            "  LTF\n",
            "  TFCILTD\n",
            "  DCBBANK\n",
            "  SANSERA\n",
            "  PRECWIRE\n",
            "  SMSPHARMA\n",
            "  BLISSGVS\n",
            "  KARURVYSYA\n",
            "  UNIONBANK\n",
            "  GENCON\n",
            "  BEL\n",
            "  BANCOINDIA\n",
            "  BANKINDIA\n",
            "  HAPPYFORGE\n",
            "  MRPL\n",
            "\n",
            "GMVP Portfolio Weights:\n",
            "----------------------------------------\n",
            "QGOLDHALF       :   44.927 %\n",
            "CUPID           :    5.106 %\n",
            "BGRENERGY       :    0.838 %\n",
            "LUMAXIND        :    1.739 %\n",
            "SABEVENTS       :    4.134 %\n",
            "POWERINDIA      :    0.000 %\n",
            "TAKE            :    2.617 %\n",
            "CUB             :    6.391 %\n",
            "AVANTIFEED      :    0.745 %\n",
            "LOTUSEYE        :    1.644 %\n",
            "TDPOWERSYS      :    0.000 %\n",
            "NETWEB          :    1.018 %\n",
            "SILVER          :    0.000 %\n",
            "CRAFTSMAN       :    5.820 %\n",
            "LTF             :    3.662 %\n",
            "TFCILTD         :    0.000 %\n",
            "DCBBANK         :    2.146 %\n",
            "SANSERA         :    1.627 %\n",
            "PRECWIRE        :    0.000 %\n",
            "SMSPHARMA       :    0.746 %\n",
            "BLISSGVS        :    0.000 %\n",
            "KARURVYSYA      :    0.092 %\n",
            "UNIONBANK       :    2.434 %\n",
            "GENCON          :    0.000 %\n",
            "BEL             :    3.797 %\n",
            "BANCOINDIA      :    0.000 %\n",
            "BANKINDIA       :    0.000 %\n",
            "HAPPYFORGE      :   10.517 %\n",
            "MRPL            :    0.000 %\n",
            "\n",
            "GMVP Performance:\n",
            "  Daily Return  :   0.2145 %\n",
            "  Daily Risk    :   0.9831 %\n",
            "  Annual Return :    54.06 %\n",
            "  Annual Risk   :    15.61 %\n",
            "\n",
            "MRR Portfolio (Max Sharpe) Weights:\n",
            "----------------------------------------\n",
            "QGOLDHALF       :   34.717 %\n",
            "CUPID           :   14.276 %\n",
            "BGRENERGY       :    9.845 %\n",
            "LUMAXIND        :    4.952 %\n",
            "SABEVENTS       :    5.776 %\n",
            "POWERINDIA      :    4.647 %\n",
            "TAKE            :    3.679 %\n",
            "CUB             :    4.273 %\n",
            "AVANTIFEED      :    1.597 %\n",
            "LOTUSEYE        :    0.000 %\n",
            "TDPOWERSYS      :    2.541 %\n",
            "NETWEB          :    0.987 %\n",
            "SILVER          :    0.000 %\n",
            "CRAFTSMAN       :    1.292 %\n",
            "LTF             :    4.221 %\n",
            "TFCILTD         :    0.000 %\n",
            "DCBBANK         :    2.442 %\n",
            "SANSERA         :    1.394 %\n",
            "PRECWIRE        :    0.454 %\n",
            "SMSPHARMA       :    0.000 %\n",
            "BLISSGVS        :    0.000 %\n",
            "KARURVYSYA      :    0.000 %\n",
            "UNIONBANK       :    2.906 %\n",
            "GENCON          :    0.000 %\n",
            "BEL             :    0.000 %\n",
            "BANCOINDIA      :    0.000 %\n",
            "BANKINDIA       :    0.000 %\n",
            "HAPPYFORGE      :    0.000 %\n",
            "MRPL            :    0.000 %\n",
            "\n",
            "MRR Performance:\n",
            "  Daily Return  :   0.3101 %\n",
            "  Daily Risk    :   1.1285 %\n",
            "  Annual Return :    78.14 %\n",
            "  Annual Risk   :    17.92 %\n",
            "\n",
            "Sharpe Ratio:\n",
            "  Daily Sharpe  :   0.2521\n",
            "  Annual Sharpe :   4.0015\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "BEST MRR PORTFOLIO\n",
            "======================================================================\n",
            "\n",
            "Companies:\n",
            "  BGRENERGY\n",
            "  QGOLDHALF\n",
            "  CUPID\n",
            "  SABEVENTS\n",
            "  LUMAXIND\n",
            "  POWERINDIA\n",
            "  TAKE\n",
            "  CUB\n",
            "  AVANTIFEED\n",
            "\n",
            "GMVP Portfolio Weights:\n",
            "----------------------------------------\n",
            "BGRENERGY       :    2.868 %\n",
            "QGOLDHALF       :   47.900 %\n",
            "CUPID           :   10.126 %\n",
            "SABEVENTS       :    7.178 %\n",
            "LUMAXIND        :    6.218 %\n",
            "POWERINDIA      :    2.720 %\n",
            "TAKE            :    4.721 %\n",
            "CUB             :   14.453 %\n",
            "AVANTIFEED      :    3.816 %\n",
            "\n",
            "GMVP Performance:\n",
            "  Daily Return  :   0.2757 %\n",
            "  Daily Risk    :   1.0657 %\n",
            "  Annual Return :    69.47 %\n",
            "  Annual Risk   :    16.92 %\n",
            "\n",
            "MRR Portfolio (Max Sharpe) Weights:\n",
            "----------------------------------------\n",
            "BGRENERGY       :   14.409 %\n",
            "QGOLDHALF       :   42.609 %\n",
            "CUPID           :   20.336 %\n",
            "SABEVENTS       :    6.916 %\n",
            "LUMAXIND        :    6.512 %\n",
            "POWERINDIA      :    3.448 %\n",
            "TAKE            :    2.702 %\n",
            "CUB             :    2.480 %\n",
            "AVANTIFEED      :    0.588 %\n",
            "\n",
            "MRR Performance:\n",
            "  Daily Return  :   0.3542 %\n",
            "  Daily Risk    :   1.2217 %\n",
            "  Annual Return :    89.26 %\n",
            "  Annual Risk   :    19.39 %\n",
            "\n",
            "Sharpe Ratio:\n",
            "  Daily Sharpe  :   0.2689\n",
            "  Annual Sharpe :   4.2693\n",
            "======================================================================\n",
            "Warning: These companies were not found:\n",
            "['ASLIND', 'AXISILVER', 'KAPSTON', 'EGOLD', 'KRISHANA', 'CMMIPL', 'GVT&D', 'UNIHEALTH', 'VMARCIND']\n",
            "\n",
            "Excel file created: best_mrr3.xlsx\n",
            "Columns exported: ['date', 'TCIEXP', 'TAKE', 'BANCOINDIA', 'KESORAMIND', 'BEL', 'LOTUSEYE', 'CRAFTSMAN', 'CUB', 'QGOLDHALF', 'SILVER', 'SABEVENTS', 'TDPOWERSYS', 'BLISSGVS', 'SANSERA', 'LUMAXIND', 'MRPL', 'PRECWIRE', 'NETWEB', 'BGRENERGY', 'HAPPYFORGE', 'GENCON', 'AVANTIFEED', 'BHARATWIRE', 'POWERINDIA', 'LTF', 'ABINFRA', 'UNIONBANK', 'BANKINDIA', 'CUPID', 'SMSPHARMA', 'TFCILTD', 'DCBBANK', 'KARURVYSYA']\n",
            "Total rows: 346\n"
          ]
        }
      ]
    }
  ]
}